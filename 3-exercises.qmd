# Exercises

### Problem 1

The diameter of a randomly selected mechanical nut is a random variable with mean 10 mm and standard deviation 0.04 mm.

a)  If $\bar X$ is the sample mean diameter of a random sample of $n=16$ nuts, where is the sampling distribution of $\bar X$ centered, and what is the standard deviation of the $\bar X$ distribution?

b)  Answer the question in (a) for a sample size of $n=64$ nuts.

c)  For which of the two random samples from (a) or (b), is $\bar X$ more likely to be within 0.01 mm from 10 mm? Explain your reasoning.

Suppose the distrution of the diameter is normal.

e)  Calculate $P(9.99\le \bar X \le 10.01)$ when $n=16$.

f)  How likely is it that the sample mean diameter exceeds 10.01 when $n=25$.

<details>

<summary>Show solutions</summary>

a)  Centered at 10 with standard deviation $\sigma/\sqrt{n}=0.04/\sqrt{16}= 0.01$.

b)  Centered at 10 with standard deviation $\sigma/\sqrt{n}=0.04/\sqrt{64}= 0.005$.

c)  With less variability, the second sample is more closely centered near 10.

d)  $P(9.99\le \bar X \le 10.01)=P(\bar X \le 10.01)-P(\bar X \le 9.99) = 0.84-0.16= 0.68$, getting the numbers from the code below:

```{python}
from scipy import stats
import numpy as np
print(
  stats.norm.cdf(10.01, loc = 10, scale = 0.04/np.sqrt(16))-
  stats.norm.cdf(9.99, loc = 10, scale = 0.04/np.sqrt(16))
  )
```

e)  $P(\bar X_{25}>10.01)=0.106$.

```{python}
print(
  1-stats.norm.cdf(10.01, loc = 10, scale = 0.04/np.sqrt(25))
  )
```

</details>

### Problem 2

The tip percentage at a restaurant has a mean value of 18% and standard deviation of 6%.

a)  What is the apporixmate probability that the sample mean tip percentage for a random sample of 40 bills is between 16% and 19%?

b)  If the sample size had been rather 15 than 40, could the probability requested in part (a) be calculated from the given information?

<details>

<summary>Show solutions</summary>

a)  With $n=40$ observations, we can approximate the probability using the central limit theorem (CLT). That is $\bar X_{40}\sim N(0.18, 0.06/\sqrt{40})$: $$P(16\%\le \bar X_{40}\le 19\%)=P(\bar X_{40}\le 19\%)-P(\bar X_{40}\le 16\%)=0.8366$$

```{python}
from scipy import stats
mean = 0.18
sd = 0.06/np.sqrt(40)
print(stats.norm.cdf(0.19, loc=mean, scale =sd)-stats.norm.cdf(0.16, loc=mean, scale = sd))
```

b)  In (a) we used the Central Limit Theorem (CLT) to approximate the probability using a normal distribution. This relies on a large enough sample size. With only $n=15$ observations, the sample size is likely too low for the CLT. If we use it anyway, we get 0.6423 for the probability.

```{python}
mean = 0.18
sd = 0.06/np.sqrt(15)
print(stats.norm.cdf(0.19, loc=mean, scale =sd)-stats.norm.cdf(0.16, loc=mean, scale = sd))
```

</details>

### Problem 3

Suppose the sugar content (g per cmÂ³) of a randomly selected fruit from a certain orchard is normally distributed with a mean of 2.65 and a standard deviation of 0.85.

a)  If a random sample of 25 fruits is selected, what is the probability that the sample average sugar content is at most 3.00? Between 2.65 and 3.00?

b)  How large a sample size would be required to ensure that the first probability in part (a) is at least 0.99?

<details>

<summary>Show solutions</summary>

a) Let $X_i$, $i=1,\ldots, 25$ denote the sugar content of 25 randomly selected fruits. We then have from the CLT that $\overline X_{25}=\frac{1}{25}\sum_{i=1}^{25}X_i$ is approximately $N(\mu,\sigma^2/n)=N(2.65, 0.85^2/25)$.

We can thus find the probabilities by

$$P(\overline X_{25} \le 3) = P\left(\frac{\overline X_{25}-\mu}{\sigma/\sqrt{n}}\le\frac{3-2.65}{0.85/\sqrt{25}}\right)=P(Z\le 2.059)=0.9802,$$
where the latter equality comes from 
```{python}
from scipy.stats import norm
print(norm.cdf(2.059))
```

$$P(\overline X_{25} \le 2.65) = P\left(\frac{\overline X_{25}-\mu}{\sigma/\sqrt{n}}\le\frac{2.65-2.65}{0.85/\sqrt{25}}\right)=P(Z\le 0)=0.5,$$
since Z is N(0,1) and the normal distribution is symmetric around its mean. We thus have that 
\begin{align*}
P(2.65\le\overline X_{25}\le 3)&=P(0\le Z\le 2.059)=P(Z\le 2.059)-P(Z\le 0)\\
&= 0.9802-05=0.4802.
\end{align*}

We could also find the probabilities without finding the Z-scores: 
```{python}
#| echo: true
import numpy as np
print("P(Xbar <= 3) = ", norm.cdf(3, loc = 2.65, scale = np.sqrt(0.0289)))
print("P(Xbar <= 2.65) = ", norm.cdf(3, loc = 2.65, scale = np.sqrt(0.0289)) - norm.cdf(2.65, loc = 2.65, scale = np.sqrt(0.0289)))
```


b)  We then need to find the value of n that satisfies:
$$P(\overline X_{n} \le 3) = P\left(\frac{\overline X_{n}-\mu}{\sigma/\sqrt{n}}\le\frac{3-2.65}{0.85/\sqrt{n}}\right)=P(Z\le \frac{0.35}{0.85}\sqrt{n})=0.99.$$
The us then find the z-score that give a probability of 0.99 using the quantile function or percent point function (the inverse of cdf): 
```{python}
#| echo: true
print(norm.ppf(0.99))
```
That is $P(Z\le 2.3263) = 0.99$, so to find $n$ we need to solve
$$\frac{0.35}{0.85}\sqrt n = 2.3263\Leftrightarrow n=2.3263^2\frac{0.85^2}{0.35^2}=31.91\approx 32.$$
Note that we round off $n$ to an integer and we should here always round up to ensure that the probability is not less than 0.99. 

</details>

### Problem 4

The Central Limit Theorem states that the sample mean $\bar X$ follows an approximately normal distribution when the sample size is sufficiently large. More precisely, the theorem asserts that the standardized version of $\bar X$ given by $$\frac{\bar X-\mu}{\sigma/\sqrt{n}},$$ converges in distribution to the standard normal distribution as $n$ increases.

How does this relate to the Law of Large Numbers? If the standardized $\bar X$ follows an approximate standard normal distribution, what does this imply about the distribution of $\bar X$ itself?

<details>

<summary>Show solutions</summary>

The Law of Large numbers states that $\bar X$ will approach $\mu$ when $n$ becomes large. The central limit theorem implies that $\bar X$ will follow a $N(\mu, \sigma^2/n)$ distribution asymptotically.

</details>

### Problem 5

Suppose $X_1, X_2, \dots, X_n$ are independent and identically distributed (i.i.d.) random variables from an exponential distribution with parameter $\lambda > 0$, i.e.,

$$f(x \mid \lambda) = \lambda e^{-\lambda x}, \quad x > 0.$$

Find the Maximum Likelihood Estimator (MLE) for $\lambda$.

<details>

<summary>Show solutions</summary>

The likelihood function is: $$L(\lambda) = \prod_{i=1}^{n} \lambda e^{-\lambda X_i} = \lambda^n e^{-\lambda \sum X_i}.$$

The log-likelihood function is: $$\ell(\lambda) = n \log \lambda - \lambda \sum X_i.$$

Differentiating with respect to $\lambda$: $$\frac{d\ell}{d\lambda} = \frac{n}{\lambda} - \sum X_i.$$

Setting it equal to zero: $$\frac{n}{\lambda} = \sum X_i.$$

Solving for $\lambda$: $$\hat{\lambda} = \frac{n}{\sum X_i}.$$

</details>

### Problem 6

Let $X_1, X_2, \dots, X_n$ be i.i.d. random variables from a normal distribution with unknown mean $\mu$ and known variance $\sigma^2$. That is, $$X_i \sim N(\mu, \sigma^2),$$ such that the density of the X's is $$f(x,\mu,\sigma)=\frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(x - \mu)^2}{2\sigma^2}\right).$$

Find the MLE of $\mu$.

<details>

<summary>Show solutions</summary>

The likelihood function is: $$L(\mu) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(X_i - \mu)^2}{2\sigma^2} \right).$$

The log-likelihood function is: $$\ell(\mu) = -\frac{n}{2} \log (2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (X_i - \mu)^2.$$

Differentiating with respect to $\mu$: $$\frac{d\ell}{d\mu} = \frac{1}{\sigma^2} \sum_{i=1}^{n} (X_i - \mu).$$

Setting it equal to zero: $$\sum_{i=1}^{n} (X_i - \mu) = 0.$$

Solving for $\mu$: $$\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} X_i.$$

</details>

### Problem 7

Let $X_1, X_2, \dots, X_n$ be i.i.d. random variables from a Bernoulli distribution with unknown parameter $p$. That is, $$P(X_i = 1) = p, \quad P(X_i = 0) = 1 - p.$$ Find the MLE for $p$.

Hint: We can also write the Bernoulli distribution as $P(X=x) =p^x(1-p)^{1-x}$, where $x\in \{0,1\}$.

<details>

<summary>Show solutions</summary>

The likelihood function is: $$L(p) = \prod_{i=1}^{n} p^{X_i} (1 - p)^{1 - X_i}.$$

The log-likelihood function is: $$\ell(p) = \sum_{i=1}^{n} X_i \log p + (1 - X_i) \log (1 - p).$$

Differentiating with respect to $p$: $$\frac{d\ell}{dp} = \sum_{i=1}^{n} \frac{X_i}{p} - \sum_{i=1}^{n} \frac{1 - X_i}{1 - p}.$$

Setting it equal to zero: $$\sum X_i \frac{1}{p} - \sum (1 - X_i) \frac{1}{1 - p} = 0.$$ Rearranging: $$\sum X_i (1 - p) = (n - \sum X_i) p.$$

Solving for $p$: $$\hat{p} = \frac{1}{n} \sum X_i.$$

</details>

### Problem 8

Let $\hat{\theta}$ be an estimator of a parameter $\theta$. The bootstrap estimate of the bias is given by:

$$\hat{\text{Bias}} = \frac{1}{B} \sum_{b=1}^{B} \hat{\theta}^*_b - \hat{\theta},$$

where $\hat{\theta}^*_b$ is the estimate from bootstrap sample $b$.

Use bootstrap resampling to estimate the bias of the maximum likelihood estimator of the variance;$$s^2=\frac1n \sum_{i}(x_i-\bar x)^2,$$ for a set of data $x_1,\ldots, x_n$.

Describe the procedure and discuss the sign of the bias. If you want to implement the code, use the following data set:

$$X = \{4.2, 3.9, 5.1, 4.8, 4.3, 5.0, 3.7, 4.5, 4.9, 4.6\}.$$

<details>

<summary>Show solutions</summary>

1.  Compute the sample variance $s^2$ from the original dataset.
2.  Generate 1000 bootstrap samples and compute $s^2$ for each.
3.  Compute the bootstrap estimate of bias using the formula above.
4.  Interpret the result: If the bias is positive, $s^2$ is overestimating the true variance; if negative, it is underestimating.

</details>

### Problem 9

When playing the casino game american roulette, there are 38 possible outcomes: 0,00, and 1-36. The 0 and 00 are colored green, while odd numbers from 1-35 are black and even numbers from 2-36 are red.

a)  What is the probability of winning if you bet on a black outcome?

A gambler has \$100 and bets \$1 each time he plays. He plays until he is either out of money or has \$150.

b)  How would you construct a Monte Carlo simulation of a situation where you always bet on black, and want to find the probability of going bankrupt.

c)  What would the probability be of the gambler reaches his goal of \$150?

<details>

<summary>Show solutions</summary>

a)  The probability of winning when betting on black is $18/38=0.474$

b)  It would make sense to use a while loop and continue to simulate unless the gambler is bankrupt or has \$200. To simulate the game, use a Bernoulli distribution for each game with success probability $18/38=0.474$. If the Bernoulli variable is 1, increase the "bank" of the gambler by 1 dollar. If it is 0, decrease it by 1 dollar. Repeat the game 10 000 times and calculate the relative frequency of going bankrupt.

```{python}
#| echo: true
import random
random.seed(123)

def simulate_game_simple(starting_money=100, goal_money=150, bet_amount=1):
    money = starting_money
    while 0 < money < goal_money:
        # Simulate the outcome: +1 with prob 18/38, -1 with prob 20/38
        outcome = random.choices([-1, 1], weights=[20, 18])[0]
        money += outcome * bet_amount
    return money == 0  # True if bankrupt

def monte_carlo_simulation(n_simulations=10000):
    bankrupt_count = sum(simulate_game_simple() for _ in range(n_simulations))
    return bankrupt_count / n_simulations

# Run the simplified simulation
estimated_prob = monte_carlo_simulation(10000)
print(f"Estimated probability of going bankrupt: {estimated_prob:.4f}")

```

c)  In the end, there are only two outcomes of the experiment. Either the gambler ends up with \$0 (bankrupt) or \$150. The probability achieving \$150 would therefore be 1-the probability of going bankrupt.

From the python simulation above, it would then be
$$1-P(bankrupt)=1-0.9949=0.0051$$

</details>

### Problem 10

Let $X_1,\ldots, X_n$ be a random sample from the probability density function $$f(x|\theta) = \theta x^{\theta -1},\quad 0<\theta<\infty,\quad 0\le x\le1.$$ Find the MLE of $\theta$.

<details>

<summary>Show solutions</summary>

$$L(\theta)=f(x_1,\ldots, x_n|\theta) = \theta^n \prod_{i=1}^nx_i^{\theta -1}$$ $$\log L = n\log \theta + (\theta-1)\sum_{i=1}^n\log x_i$$ $$\frac{\partial \log L}{\partial \theta} = \frac{n}{\theta} + \sum_{i=1}^n\log x_i=0$$ $$\widehat \theta = \frac{-n}{\sum_{i=1}^n \log x_i}.$$

</details>
