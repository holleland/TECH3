<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>exercises – TECH3 Applied statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./4-intro.html" rel="next">
<link href="./3-python.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-37d81edd14c5e89b87cd66af6a72e2e5.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./images/nhh.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">TECH3 Applied statistics</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./calender.html"> 
<span class="menu-text">Calender</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./1-intro.html" aria-current="page"> 
<span class="menu-text">Modules</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./seminar1.html"> 
<span class="menu-text">Seminars</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./datalabs.html"> 
<span class="menu-text">Datalabs</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./oldexams.html"> 
<span class="menu-text">Old exams</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./3-intro.html">Module 3: Estimation, sampling distributions and resampling</a></li><li class="breadcrumb-item"><a href="./3-exercises.html">Exercises</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 1: Summarizing and visualizing data</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-textbook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Textbook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-statistical-thinking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistical Thinking</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-working-with-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Working with data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-summarizing-data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summarizing data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-summary-statistics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Summary statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-data-visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data visualization principles</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-plotting-tools.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Plotting tools</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-idealised_representations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Idealised representations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-gapminder.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Gapminder example of good visualization</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 2: Probability, random variables, probability distributions and simulations.</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-textbook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Textbook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-what-is-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is probability?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-basic-concepts-in-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic concepts in probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-basic-probability-rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic probability rules</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-conditional-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conditional probability</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-independent-events.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Independent events</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-bayes-rule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bayes rule</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-discrete-random-variables-and-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discrete random variables and distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-exp-var-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Expectation and variance of discrete random variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 3: Estimation, sampling distributions and resampling</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-textbook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Textbook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-population-vs-sample.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Population vs sample</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-what-is-a-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is a model?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-sampling-error.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sampling error and distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-central-limit-theorem.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Central Limit Theorem</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-what-is-an-estimator.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">What is an estimator?</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-maximum-likelihood.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Maximum likelihood</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-random-number-generation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random number generation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-monte-carlo-simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Monte Carlo simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bootstrap</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./3-exercises.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 4: Designing studies, hypothesis testing, and quantifying effects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-textbook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Textbook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-hypothesis-testing.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hypothesis testing</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-hypothesis-testing-in-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hypothesis testing in Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-power-analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Power analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-videos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Videos</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./4-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Module 5: Measuring relationships and fitting models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-textbook.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Textbook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-categorical-relationships.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling categorical relationships</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-contingency-tables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contingency tables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-simpsons-paradox.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simpson’s paradox</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-continuous-relationships-correlation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Modeling continuous relationships: Correlation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-correlation-and-causation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Correlation and causation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-linear-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-assessing-the-model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Assessing the model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-prediction-models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prediction models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-logistic-regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Logistic regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Python</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./5-exercises.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exercises</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#exercises" id="toc-exercises" class="nav-link active" data-scroll-target="#exercises">Exercises</a>
  <ul class="collapse">
  <li><a href="#problem-1" id="toc-problem-1" class="nav-link" data-scroll-target="#problem-1">Problem 1</a></li>
  <li><a href="#problem-2" id="toc-problem-2" class="nav-link" data-scroll-target="#problem-2">Problem 2</a></li>
  <li><a href="#problem-3" id="toc-problem-3" class="nav-link" data-scroll-target="#problem-3">Problem 3</a></li>
  <li><a href="#problem-4" id="toc-problem-4" class="nav-link" data-scroll-target="#problem-4">Problem 4</a></li>
  <li><a href="#problem-5" id="toc-problem-5" class="nav-link" data-scroll-target="#problem-5">Problem 5</a></li>
  <li><a href="#problem-6" id="toc-problem-6" class="nav-link" data-scroll-target="#problem-6">Problem 6</a></li>
  <li><a href="#problem-7" id="toc-problem-7" class="nav-link" data-scroll-target="#problem-7">Problem 7</a></li>
  <li><a href="#problem-8" id="toc-problem-8" class="nav-link" data-scroll-target="#problem-8">Problem 8</a></li>
  <li><a href="#problem-9" id="toc-problem-9" class="nav-link" data-scroll-target="#problem-9">Problem 9</a></li>
  <li><a href="#problem-10" id="toc-problem-10" class="nav-link" data-scroll-target="#problem-10">Problem 10</a></li>
  <li><a href="#problem-11" id="toc-problem-11" class="nav-link" data-scroll-target="#problem-11">Problem 11</a></li>
  <li><a href="#problem-12" id="toc-problem-12" class="nav-link" data-scroll-target="#problem-12">Problem 12</a></li>
  <li><a href="#problem-13" id="toc-problem-13" class="nav-link" data-scroll-target="#problem-13">Problem 13</a></li>
  <li><a href="#problem-14" id="toc-problem-14" class="nav-link" data-scroll-target="#problem-14">Problem 14</a></li>
  <li><a href="#problem-15" id="toc-problem-15" class="nav-link" data-scroll-target="#problem-15">Problem 15</a></li>
  <li><a href="#problem-16" id="toc-problem-16" class="nav-link" data-scroll-target="#problem-16">Problem 16</a></li>
  <li><a href="#problem-17" id="toc-problem-17" class="nav-link" data-scroll-target="#problem-17">Problem 17</a></li>
  <li><a href="#problem-18" id="toc-problem-18" class="nav-link" data-scroll-target="#problem-18">Problem 18</a></li>
  <li><a href="#problem-19" id="toc-problem-19" class="nav-link" data-scroll-target="#problem-19">Problem 19</a></li>
  <li><a href="#problem-20" id="toc-problem-20" class="nav-link" data-scroll-target="#problem-20">Problem 20</a></li>
  <li><a href="#problem-21" id="toc-problem-21" class="nav-link" data-scroll-target="#problem-21">Problem 21</a></li>
  <li><a href="#problem-22" id="toc-problem-22" class="nav-link" data-scroll-target="#problem-22">Problem 22</a></li>
  <li><a href="#problem-23" id="toc-problem-23" class="nav-link" data-scroll-target="#problem-23">Problem 23</a></li>
  <li><a href="#problem-24" id="toc-problem-24" class="nav-link" data-scroll-target="#problem-24">Problem 24</a></li>
  <li><a href="#problem-25" id="toc-problem-25" class="nav-link" data-scroll-target="#problem-25">Problem 25</a></li>
  <li><a href="#problem-26" id="toc-problem-26" class="nav-link" data-scroll-target="#problem-26">Problem 26</a></li>
  <li><a href="#problem-27" id="toc-problem-27" class="nav-link" data-scroll-target="#problem-27">Problem 27</a></li>
  <li><a href="#problem-28" id="toc-problem-28" class="nav-link" data-scroll-target="#problem-28">Problem 28</a></li>
  <li><a href="#problem-29" id="toc-problem-29" class="nav-link" data-scroll-target="#problem-29">Problem 29</a></li>
  <li><a href="#problem-30" id="toc-problem-30" class="nav-link" data-scroll-target="#problem-30">Problem 30</a></li>
  <li><a href="#problem-31" id="toc-problem-31" class="nav-link" data-scroll-target="#problem-31">Problem 31</a></li>
  <li><a href="#problem-32" id="toc-problem-32" class="nav-link" data-scroll-target="#problem-32">Problem 32</a></li>
  <li><a href="#problem-33" id="toc-problem-33" class="nav-link" data-scroll-target="#problem-33">Problem 33</a></li>
  <li><a href="#problem-34" id="toc-problem-34" class="nav-link" data-scroll-target="#problem-34">Problem 34</a></li>
  <li><a href="#problem-35" id="toc-problem-35" class="nav-link" data-scroll-target="#problem-35">Problem 35</a></li>
  <li><a href="#problem-36" id="toc-problem-36" class="nav-link" data-scroll-target="#problem-36">Problem 36</a></li>
  <li><a href="#problem-37" id="toc-problem-37" class="nav-link" data-scroll-target="#problem-37">Problem 37</a></li>
  <li><a href="#problem-38" id="toc-problem-38" class="nav-link" data-scroll-target="#problem-38">Problem 38</a></li>
  <li><a href="#problem-39" id="toc-problem-39" class="nav-link" data-scroll-target="#problem-39">Problem 39</a></li>
  <li><a href="#problem-40" id="toc-problem-40" class="nav-link" data-scroll-target="#problem-40">Problem 40</a></li>
  <li><a href="#problem-41" id="toc-problem-41" class="nav-link" data-scroll-target="#problem-41">Problem 41</a></li>
  <li><a href="#problem-42" id="toc-problem-42" class="nav-link" data-scroll-target="#problem-42">Problem 42</a></li>
  <li><a href="#problem-43" id="toc-problem-43" class="nav-link" data-scroll-target="#problem-43">Problem 43</a></li>
  <li><a href="#problem-44" id="toc-problem-44" class="nav-link" data-scroll-target="#problem-44">Problem 44</a></li>
  <li><a href="#problem-45" id="toc-problem-45" class="nav-link" data-scroll-target="#problem-45">Problem 45</a></li>
  <li><a href="#problem-46" id="toc-problem-46" class="nav-link" data-scroll-target="#problem-46">Problem 46</a></li>
  <li><a href="#problem-47" id="toc-problem-47" class="nav-link" data-scroll-target="#problem-47">Problem 47</a></li>
  <li><a href="#problem-48" id="toc-problem-48" class="nav-link" data-scroll-target="#problem-48">Problem 48</a></li>
  <li><a href="#problem-49" id="toc-problem-49" class="nav-link" data-scroll-target="#problem-49">Problem 49</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./3-intro.html">Module 3: Estimation, sampling distributions and resampling</a></li><li class="breadcrumb-item"><a href="./3-exercises.html">Exercises</a></li></ol></nav></header>




<section id="exercises" class="level1">
<h1>Exercises</h1>
<section id="problem-1" class="level3">
<h3 class="anchored" data-anchor-id="problem-1">Problem 1</h3>
<p>A university wants to study the average number of hours students sleep during finals week. They decide to gather data by surveying students.</p>
<ol type="a">
<li><p>What is the <strong>population</strong> of this study?</p></li>
<li><p>Give an example of a possible <strong>sample</strong>.</p></li>
<li><p>Why is it important to distinguish between a population and a sample?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The <strong>population</strong> is all students at the university during finals week. Recall that tthe population is the <strong>whole</strong> group we want to study.</p></li>
<li><p>A <strong>sample</strong> might be 150 students selected randomly from various departments. A sample cam really be **any* subset of the population, however, that does not mean that all samples are created equally. (This will be discussed more later)</p></li>
<li><p>It’s important to distinguish between a population and a sample because we <em>usually</em> cannot study the entire population. Instead, we use a sample to make <strong>inferences</strong> about the population. Understanding this distinction helps us evaluate the <strong>reliability</strong> and <strong>limitations</strong> of our conclusions.</p></li>
</ol>
</details>
</section>
<section id="problem-2" class="level3">
<h3 class="anchored" data-anchor-id="problem-2">Problem 2</h3>
<p>A university wants to study the average number of hours students sleep during finals week. They decide to gather data by surveying students.</p>
<p>Suppose the researcher only surveys students from the university’s Mathematics department. What potential issue arises from this sampling choice?</p>
<details>
<summary>
Show solutions
</summary>
<p>Surveying only Mathematics students would certainly introduce some degree of <strong>sampling bias</strong>. We can’t be certain that the sleep habits of students in the maths department would have similar habits to the average student. There could for instance be differences in workload and culture from one department to the next. Thus, we can’t safely generalise the findings, by looking only at the maths department.</p>
</details></section>
<section id="problem-3" class="level3">
<h3 class="anchored" data-anchor-id="problem-3">Problem 3</h3>
<p>Suppose a public health organization wants to estimate the average number of daily steps taken by adults in a large city.</p>
<ol type="a">
<li><p>What are some key features the sample should have to be considered <strong>representative</strong> of the adult population.</p></li>
<li><p>In what way could one go about achieving a representative sample?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>A representative sample <strong>needs</strong> to reflect the characteristics, proportions, and diversity of the of the entire population. I.e. there people of different ages, sexes and lifestyles should be <strong>proportionally</strong> (at least somewhat proportionally) represented in the sample, for it to be representative of the entire population.</p></li>
<li><p>The simplest way is to just select randomly from the entire population. Even though each pick is completely random, by the law of large numbers, once enough people are picked at random, the sample distribution should will approach the population’s. This isn’t always certain to work, as it mostly relies on having a sample of adequate size, as well asd needing to ensure that one is sampling form the <strong>entire</strong> population at random, and not a subset of it.</p></li>
</ol>
<p>One useful method could be <strong>stratified sampling</strong>, where the population is divided into key subgroups (e.g., age groups, districts), and individuals are randomly selected from each subgroup. This ensures balanced representation across important variables.</p>
</details>
</section>
<section id="problem-4" class="level3">
<h3 class="anchored" data-anchor-id="problem-4">Problem 4</h3>
<p>Like in Problem 3, suppose a public health organization wants to estimate the average number of daily steps taken by adults in a large city. Suppose now also that some people choose not to respond. Could this possibly cause problems for the surveyors?</p>
<details>
<summary>
Show solutions
</summary>
<p>Imagine if there was some significant distinction in <strong>attributes</strong> between the people that chose to reply, and of those who chose not to. I.e., those who reply and those who don’t aren’t necessarily random. This non-randomness in response could veyr well compromise the representative sample that we are looking for. Imagine that less active adults were less likely to respond than more active ones. In a scenario like this, the public health organisation might end up overestimating the average number of daily steps.</p>
</details>
</section>
<section id="problem-5" class="level3">
<h3 class="anchored" data-anchor-id="problem-5">Problem 5</h3>
<p>A new coffee shop wants to know what people think about their service. They post a feedback form on their website and collect responses for a week.</p>
<ol type="a">
<li><p>Identify one <strong>source of sampling bias</strong> in this method.</p></li>
<li><p>Propose an <strong>alternative approach</strong> that would reduce sampling bias.</p></li>
</ol>
<details>
<summary>
<strong>Show solutions</strong>
</summary>
<ol type="a">
<li><p>The main bias comes from <strong>self-selection</strong>: only people who visit the website and feel strongly (either positively or negatively) are likely to respond. This could lead to results that do not reflect the general customer base.</p></li>
<li><p>A better approach would be to <strong>randomly select</strong> customers in-store and ask them to complete a short survey, or to distribute surveys with receipts to all customers during the week, encouraging broad participation. This reduces self-selection bias and captures more typical opinions.</p></li>
</ol>
</details>
</section>
<section id="problem-6" class="level3">
<h3 class="anchored" data-anchor-id="problem-6">Problem 6</h3>
<p>You are conducting a study on the eating habits of university level students in Bergen. You want your results to generalize well to the full student population.</p>
<ol type="a">
<li><p>Suggest a <strong>sampling method</strong> that would help ensure your sample is representative.</p></li>
<li><p>What steps could you take to avoid <strong>overrepresenting</strong> certain types of students (e.g.&nbsp;from large universities or urban areas)?</p></li>
<li><p>What issues could you run into if you only sampled students from NHH?</p></li>
</ol>
<details>
<summary>
<strong>Show solutions</strong>
</summary>
<ol type="a">
<li><p>A good choice would be <strong>stratified random sampling</strong>. You could divide the college student population by school type (e.g., large universities, community colleges, private colleges), and then randomly select students from each group proportionally.</p></li>
<li><p>To avoid overrepresentation, ensure that each subgroup is sampled <strong>in proportion to its size</strong> in the overall student population. For example, if 30% of students are from smaller schools, then 30% of your sample should come from smaller schools too. You might also apply <strong>weighting</strong> to adjust for any imbalance in response rates after collecting the data.</p></li>
<li><p>Though it may be more convenient for you to only sample NHH students, we are trying to consider the eating habits of the general student in Bergen. Looking only at NHH could very well lead to biased results, especially considering that NHH is far less diverse in field of study than institutions like UiB and HVL. a random sampling of all students, or a stratified sampling, would clearly lead to much more statistically rigorous results in a case liek this.</p></li>
</ol>
</details>
</section>
<section id="problem-7" class="level3">
<h3 class="anchored" data-anchor-id="problem-7">Problem 7</h3>
<p>A news article reports: <em>“80% of people in the city support the new policy,”</em> based on a poll conducted by a political advocacy group on their own social media page.</p>
<ol type="a">
<li><p>Explain why the results of this poll may be <strong>biased</strong>.</p></li>
<li><p>Suggest a way to <strong>improve</strong> the sampling process to obtain more reliable public opinion data.</p></li>
<li><p>Suppose a truly random sample of city residents shows only 45% support for the policy. How does this compare to the original poll, and what does it suggest?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The sample is likely <strong>biased</strong> because it seems likely that very few non-followers of the party would respond to this survey, as the poll was conducted on <strong>their</strong> page. These followers may already share similar views, making them <strong>not representative</strong> of the broader city population.</p></li>
<li><p>A better approach would be to conduct a <strong>randomized phone or email survey</strong> using a list of registered voters or residents. Alternatively, partnering with an independent polling organization that uses techniques like random digit dialing or address-based sampling could provide more reliable and representative data.</p></li>
<li><p>This suggests that the original 80% figure was inflated due to sampling bias. A truly random sample showing only 45% support reveals that the earlier poll was not representative of the general population. It highlights how non-random or biased sampling can lead to misleading conclusions.</p></li>
</ol>
</details>
</section>
<section id="problem-8" class="level3">
<h3 class="anchored" data-anchor-id="problem-8">Problem 8</h3>
<p>Suppose you’re studying how the number of hours a student studies per week relates to their exam score. You propose the following relationship:</p>
<p><span class="math display">\[
\text{Exam Score} = 5 \times \text{Study Hours} + \varepsilon
\]</span></p>
<ol type="a">
<li><p>What is the <strong>deterministic part</strong> (non-random part) of this model?</p></li>
<li><p>What does the <strong>error term</strong> <span class="math inline">\(\varepsilon\)</span> represent?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>The deterministic part is:</li>
</ol>
<p><span class="math display">\[
\text{Exam Score} = 5 \times \text{Study Hours}
\]</span></p>
<p>This is the part of the model that gives a fixed prediction based only on the number of study hours. I.e. the part of the model that is not randomly determined.</p>
<ol start="2" type="a">
<li>The error term <span class="math inline">\(\varepsilon\)</span> accounts for <strong>everything else</strong> that affects the exam score but isn’t included in the model — such as test anxiety, sleep, prior knowledge, or randomness. It reflects <strong>unexplained variation</strong>.</li>
</ol>
</details>
</section>
<section id="problem-9" class="level3">
<h3 class="anchored" data-anchor-id="problem-9">Problem 9</h3>
<p>You collect data on 5 students and fit a statistical model to predict exam scores from study hours. The model predicts:</p>
<p><span class="math display">\[
\hat{y}_i = 5 \times x_i
\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is the number of hours student <span class="math inline">\(i\)</span> studied. Karl studied for 6 hours, and his final score ended up being 35.</p>
<ol type="a">
<li><p>What was Karl’s <strong>predicted score</strong>?</p></li>
<li><p>What is the <strong>residual</strong> for Karl?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Since Karl studied for 6 hours we get that <span class="math inline">\(x_i=6\)</span>. Now we have everything we need to compute the predicted score. The predicted score is:</li>
</ol>
<p><span class="math display">\[
\hat{y}_i = 5 \times 6 = 30
\]</span></p>
<ol start="2" type="a">
<li>The residual is the difference between the predicted score and the actual score. Recall that the predicted score we found in a) was 30 and the actual score was 35. With this we can compute the residual. The residual is:</li>
</ol>
<p><span class="math display">\[
\text{Residual} = y_i - \hat{y}_i = 35 - 30 = 5
\]</span></p>
<p>This means Karl did <strong>5 points better</strong> than the model predicted.</p>
</details>
</section>
<section id="problem-10" class="level3">
<h3 class="anchored" data-anchor-id="problem-10">Problem 10</h3>
<p>A model assumes the error terms <span class="math inline">\(\varepsilon_1, \varepsilon_2, \dots, \varepsilon_n\)</span> are <strong>identically distributed</strong>.</p>
<ol type="a">
<li><p>What does it mean for the error terms to be <strong>identically distributed</strong>?</p></li>
<li><p>Why might this assumption be important when building a statistical model?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>Identically distributed means that <strong>each error term comes from the same probability distribution</strong> — e.g., all errors are normally distributed with the same mean and variance.</p></li>
<li><p>This assumption ensures that the <strong>variability is consistent</strong> across observations. If errors had different distributions (e.g.&nbsp;wider for some groups than others), then the model’s predictions could be <strong>unreliable or biased</strong> for certain parts of the data.</p></li>
</ol>
</details>
</section>
<section id="problem-11" class="level3">
<h3 class="anchored" data-anchor-id="problem-11">Problem 11</h3>
<p>Now assume the model from problem 10 also requires the error terms <span class="math inline">\(\varepsilon_1, \varepsilon_2, \dots, \varepsilon_n\)</span> to be <strong>independent</strong>. This means the error terms (residuals) are now independent and identically distributed (i.i.d.).</p>
<ol type="a">
<li><p>What does it mean for error terms to be <strong>independent</strong>?</p></li>
<li><p>Provide a situation where this assumption might be <strong>violated</strong>.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>Independent error terms mean that the value of one error term <strong>does not provide any information</strong> about another. The errors are <strong>not correlated</strong> and have no systematic pattern between them.</p></li>
<li><p>A violation might occur in <strong>time series data</strong> (e.g.&nbsp;daily stock prices), where today’s error may be related to yesterday’s. Another example is when <strong>data points come from the same individual</strong> (e.g.&nbsp;repeated measures), introducing <strong>dependency</strong> between observations.</p></li>
</ol>
</details>
</section>
<section id="problem-12" class="level3">
<h3 class="anchored" data-anchor-id="problem-12">Problem 12</h3>
<p>You take a random sample of 50 students from a large university to estimate the average number of hours they sleep per night. The sample mean is 6.8 hours, while the true population mean (which you happen to know) is 7.1 hours.</p>
<ol type="a">
<li><p>What is the <strong>sampling error</strong> in this situation?</p></li>
<li><p>Why does sampling error occur, even when using random sampling?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Recall that to find the sampling error we need ot subtract the population value <span class="math inline">\(\mu\)</span> form the sample value <span class="math inline">\(\overline{y}\)</span>. We see here that he nsample mean is given by the average we find through our experiment <span class="math inline">\(\overline{y}=6.8\)</span> and the population value is also given <span class="math inline">\(\mu=7.1\)</span>.</li>
</ol>
<p><span class="math display">\[
\text{Sampling error} = \overline{y} - \mu = 6.8 - 7.1 = -0.3
\]</span> I.e. our sample underestimated the true value by 0.3 hours, which is 18 minutes.</p>
<ol start="2" type="a">
<li>Sampling error occurs because we are only using <strong>a subset of the population</strong>, and that subset may not perfectly reflect the whole population due to <strong>natural variability</strong>. Even random samples will vary from sample to sample, producing different estimates.</li>
</ol>
</details>
</section>
<section id="problem-13" class="level3">
<h3 class="anchored" data-anchor-id="problem-13">Problem 13</h3>
<p>Suppose you repeatedly take samples of size 30 from a population with a true mean of 50 and plot the means of those samples.</p>
<ol type="a">
<li><p>What is this collection of sample means called?</p></li>
<li><p>As you increase the number of samples, what does the shape of this distribution tend to look like?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The collection of sample means is called the <strong>sampling distribution of the sample mean</strong>.</p></li>
<li><p>According to the <strong>Central Limit Theorem</strong>, the sampling distribution will tend to become <strong>approximately normal</strong>, even if the original population is not normally distributed — provided the sample size is large enough.</p></li>
</ol>
<p>Have a look at the figures below to see an example of how a sample distribution may look and develop as an experiment is repeated. Note how teh figures approach a bell curve.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Population: non-normal (exponential) to highlight the CLT</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="fl">1.0</span>, size<span class="op">=</span><span class="dv">100000</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">30</span>  <span class="co"># Fixed sample size</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to simulate means</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sample_means(num_samples):</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [np.mean(np.random.choice(population, n, replace<span class="op">=</span><span class="va">True</span>)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(num_samples)]</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate with increasing number of samples</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>means_10 <span class="op">=</span> sample_means(<span class="dv">10</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>means_100 <span class="op">=</span> sample_means(<span class="dv">100</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>means_1000 <span class="op">=</span> sample_means(<span class="dv">1000</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">4</span>))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'skyblue'</span>, <span class="st">'orange'</span>, <span class="st">'seagreen'</span>]</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [means_10, means_100, means_1000]</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>titles <span class="op">=</span> [<span class="st">"10 Samples"</span>, <span class="st">"100 Samples"</span>, <span class="st">"1000 Samples"</span>]</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax, data, color, title <span class="kw">in</span> <span class="bu">zip</span>(axs, samples, colors, titles):</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    ax.hist(data, bins<span class="op">=</span><span class="dv">10</span> <span class="cf">if</span> title <span class="op">==</span> <span class="st">"10 Samples"</span> <span class="cf">else</span> <span class="dv">20</span> <span class="cf">if</span> title <span class="op">==</span> <span class="st">"100 Samples"</span> <span class="cf">else</span> <span class="dv">30</span>,</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            color<span class="op">=</span>color, edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    ax.set_xlim(<span class="dv">0</span>, <span class="dv">3</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">"Sample Mean"</span>)</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">"Frequency"</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="3-exercises_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="1440"></p>
</figure>
</div>
</div>
</div>
</details>
</section>
<section id="problem-14" class="level3">
<h3 class="anchored" data-anchor-id="problem-14">Problem 14</h3>
<p>You are estimating the average test score for a population. The population has a standard deviation of <span class="math inline">\(\sigma = 10\)</span>.</p>
<ol type="a">
<li><p>What is the standard deviation of the sample mean (also called the <strong>standard error</strong>) if you take a sample of size <span class="math inline">\(n = 25\)</span>?</p></li>
<li><p>What happens to the standard error if you increase the sample size to <span class="math inline">\(n = 100\)</span>?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Recall that so find the standard deviation of the sample mean we use the formula <span class="math display">\[SD\left(\overline{Y}_n \right)=\frac{\sigma}{\sqrt{n}} \]</span> Since we already know <span class="math inline">\(n=25\)</span> and <span class="math inline">\(\sigma=10\)</span> we can easily compute the standard error. The standard error is given by:</li>
</ol>
<p><span class="math display">\[
SD\left(\overline{Y}_n \right) = \frac{\sigma}{\sqrt{n}} = \frac{10}{\sqrt{25}} = \frac{10}{5} = 2
\]</span></p>
<ol start="2" type="a">
<li>If <span class="math inline">\(n = 100\)</span>:</li>
</ol>
<p><span class="math display">\[
\text{SE} = \frac{10}{\sqrt{100}} = \frac{10}{10} = 1
\]</span></p>
<p>So, increasing the sample size <strong>reduces the standard error</strong>, meaning the sample mean becomes more <strong>precise</strong>.</p>
</details>
</section>
<section id="problem-15" class="level3">
<h3 class="anchored" data-anchor-id="problem-15">Problem 15</h3>
<p>Imagine you take 1,000 different random samples, each of size 40, from the same population. You compute the mean for each sample and plot a histogram.</p>
<ol type="a">
<li><p>What does the center of the sampling distribution represent?</p></li>
<li><p>How does the <strong>spread</strong> of this histogram relate to sample size?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The center of the sampling distribution represents the <strong>population mean</strong> (or it will at least be <strong>very</strong> close to the population mean). On average, the sample means will be centered around the true population mean.</p></li>
<li><p>The spread of the sampling distribution — measured by the <strong>standard error</strong> — <strong>decreases as the sample size increases</strong>. This means larger samples lead to <strong>less variability</strong> in the sample mean.I.e., we will see the the shape of the distribution close in on the population mean as the the sample size incereases.</p></li>
</ol>
<p>Take a look at the representation below to get an idea. The red line represents the population mean, and as the sample size increases the distribution of sample means becomes tighter around it, i.e.&nbsp;more observations are relatively close to the true population mean when n increases. This is the idea when we compute the standard error and notice that it <strong>decreases</strong> in n.&nbsp;this is also an effective illustration of the central limit theorem <strong>and</strong> the law of large numbers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewed population: Exponential</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>population <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="fl">1.0</span>, size<span class="op">=</span><span class="dv">100000</span>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>mu_true <span class="op">=</span> np.mean(population)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to generate sampling distributions</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_means_by_n(n, reps<span class="op">=</span><span class="dv">1000</span>):</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    sample_means <span class="op">=</span> [np.mean(np.random.choice(population, n, replace<span class="op">=</span><span class="va">True</span>)) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(reps)]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame({</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sample_mean'</span>: sample_means,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sample_size'</span>: <span class="ss">f'n = </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    simulate_means_by_n(<span class="dv">5</span>),</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    simulate_means_by_n(<span class="dv">30</span>),</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    simulate_means_by_n(<span class="dv">100</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot sampling distributions</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>(style<span class="op">=</span><span class="st">"whitegrid"</span>, font_scale<span class="op">=</span><span class="fl">1.2</span>)<span class="op">;</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> sns.FacetGrid(df, col<span class="op">=</span><span class="st">"sample_size"</span>, sharey<span class="op">=</span><span class="va">False</span>, height<span class="op">=</span><span class="dv">4</span>, aspect<span class="op">=</span><span class="fl">1.2</span>)<span class="op">;</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>g.<span class="bu">map</span>(sns.histplot, <span class="st">"sample_mean"</span>, kde<span class="op">=</span><span class="va">True</span>, stat<span class="op">=</span><span class="st">"density"</span>, bins<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">"lightblue"</span>, edgecolor<span class="op">=</span><span class="st">"white"</span>)<span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Add vertical line for population mean</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ax <span class="kw">in</span> g.axes.flat:</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    ax.axvline(mu_true, color<span class="op">=</span><span class="st">"red"</span>, linestyle<span class="op">=</span><span class="st">"--"</span>, linewidth<span class="op">=</span><span class="dv">1</span>)<span class="op">;</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>g.set_axis_labels(<span class="st">"Sample Mean"</span>, <span class="st">"Density"</span>)<span class="op">;</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>g.fig.suptitle(<span class="st">"Effect of Sample Size on the Sampling Distribution of the Mean"</span>, y<span class="op">=</span><span class="fl">1.05</span>)<span class="op">;</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="3-exercises_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="1382"></p>
</figure>
</div>
</div>
</div>
</details>
</section>
<section id="problem-16" class="level3">
<h3 class="anchored" data-anchor-id="problem-16">Problem 16</h3>
<p>You simulate the following experiment using software: (You don’t <strong>need</strong> to do this in Python yourself, but it could be a neat exercise to see it for yourself fully.)</p>
<ul>
<li>Draw 1,000 random samples of size <span class="math inline">\(n = 30\)</span> from a population with mean <span class="math inline">\(\mu = 100\)</span> and standard deviation <span class="math inline">\(\sigma = 15\)</span>.</li>
<li>For each sample, compute the sample mean and store it.</li>
<li>Plot the histogram of all 1,000 sample means.</li>
</ul>
<ol type="a">
<li><p>What shape do you expect the histogram of sample means to have?</p></li>
<li><p>Approximately where should the <strong>center</strong> of the histogram be?</p></li>
<li><p>If you were to repeat the experiment with a larger sample size <span class="math inline">\(n = 100\)</span>, what change would you expect in the <strong>spread</strong> of the histogram?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The histogram should be approximately <strong>normal (bell-shaped)</strong> due to the <strong>Central Limit Theorem</strong>, even if the original population is not normal.</p></li>
<li><p>The center should be at or very near the <strong>population mean</strong>, which is <span class="math inline">\(\mu = 100\)</span>.</p></li>
<li><p>The spread — measured by the <strong>standard error</strong> — would <strong>decrease</strong>. A larger sample size makes the sample means more concentrated around the population mean. Mathematically: (<span class="math inline">\(SE\)</span> is an equivalent notation for the standard error)</p></li>
</ol>
<p><span class="math display">\[
\text{SE}_{30} = \frac{15}{\sqrt{30}} \approx 2.74, \quad \text{SE}_{100} = \frac{15}{10} = 1.5
\]</span></p>
</details>
</section>
<section id="problem-17" class="level3">
<h3 class="anchored" data-anchor-id="problem-17">Problem 17</h3>
<p>A researcher wants to estimate the average amount of money undergraduate students at a large university spend on food per week. She:</p>
<ol type="1">
<li>Randomly selects 40 students and records their weekly food spending.</li>
<li>Computes the <strong>sample mean</strong>: <span class="math inline">\(\mu=\$52.80\)</span>.</li>
<li>Knows from prior studies that the <strong>population standard deviation</strong> is approximately <span class="math inline">\(\sigma=\$12\)</span>.</li>
</ol>
<!-- -->
<ol type="a">
<li><p>What is the <strong>sampling error</strong> if the actual population mean is $50?</p></li>
<li><p>What is the <strong>standard error</strong> of the sample mean?</p></li>
<li><p>Explain what would happen to the standard error if she used a sample of 160 students instead.</p></li>
<li><p>Is this one sample mean likely to equal the population mean exactly? Why or why not?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>We have a sample mean <span class="math inline">\(\overline{y}=52.80\)</span>, so then we should just subtract the population mean to compute the sampling error.</li>
</ol>
<p><span class="math display">\[
\text{Sampling error} = 52.80 - 50 = 2.80
\]</span></p>
<ol start="2" type="a">
<li>We can easily compute this as we already know the population standard deviation <span class="math inline">\(\sigma=12\)</span>, and the sample size <span class="math inline">\(n=40\)</span>.</li>
</ol>
<p><span class="math display">\[
\text{SE} = \frac{12}{\sqrt{40}} \approx \frac{12}{6.32} \approx 1.90
\]</span></p>
<ol start="3" type="a">
<li>If <span class="math inline">\(n = 160\)</span>:</li>
</ol>
<p><span class="math display">\[
\text{SE} = \frac{12}{\sqrt{160}} \approx \frac{12}{12.65} \approx 0.95
\]</span></p>
<p>So the standard error would <strong>shrink</strong>, improving precision.</p>
<ol start="4" type="a">
<li>It is <strong>unlikely</strong> that the sample mean equals the population mean exactly. Due to <strong>sampling variability</strong>, different random samples will produce different estimates, though they should cluster around the true mean if the sample is representative. It will also be **likelier* that there is less of an absolute difference between the sample mean and population mean as the sample size increases, as this will reduce standard error. As illustrated in c), this effect improves precision.</li>
</ol>
</details>
</section>
<section id="problem-18" class="level3">
<h3 class="anchored" data-anchor-id="problem-18">Problem 18</h3>
<p>You’re given a population distribution with unknown form. However, you’re told the population has finite mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. You draw a simple random sample of size <span class="math inline">\(n\)</span>, and compute the sample mean <span class="math inline">\(\overline{X}_n\)</span>.</p>
<ol type="a">
<li><p>According to the Central Limit Theorem (CLT), what is the <strong>asymptotic distribution</strong> of <span class="math inline">\(\overline{X}_n\)</span> as <span class="math inline">\(n \to \infty\)</span>?</p></li>
<li><p>What does the CLT <strong>not</strong> guarantee when <span class="math inline">\(n\)</span> is small?</p></li>
<li><p>Illustrate the two following results given the sample of size <span class="math inline">\(n\)</span> given in this problem.</p></li>
<li><p><span class="math display">\[E\left[\overline{X}_n\right]=\mu\]</span></p></li>
</ol>
<!-- -->
<ol start="2" type="i">
<li><span class="math display">\[ Var \left[\overline{X}_n \right]=\frac{\sigma^2}{n} \]</span></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>The CLT tells us that a that a sequence of independent and identically distributed (i.i.d) random variables <span class="math inline">\(X_1,\dots, X_n\)</span>, with a an expected value <span class="math inline">\(\mu\)</span> and a finite variance <span class="math inline">\(\sigma^2\)</span> will have their average converge to a normal distribution, when <span class="math inline">\(n\)</span> approaches infinity (<span class="math inline">\(n\rightarrow \infty\)</span>). The average of these <span class="math inline">\(n\)</span> variables we give as normal</li>
</ol>
<p><span class="math display">\[\overline{X}_n=\frac{1}{n}\sum^n_{i=1}X_i \]</span> The normal distribution is decided by <strong>two</strong> parameters; mean and variance. So to find exactly which distribution the CLT has <span class="math inline">\(\overline{X}_n\)</span> converge to we need the mean and variance. The rule from the lectures tells us that the mean of this normal distribution will remain the same as for <span class="math inline">\(X_i\)</span>, i.e.&nbsp;<span class="math inline">\(\mu\)</span> and that the variance will converge to <span class="math inline">\(\frac{\sigma^2}{n}\)</span></p>
<p>In short the CLT then says:</p>
<p><span class="math display">\[
\bar{X}_n \xrightarrow{d} \mathcal{N}\left(\mu, \frac{\sigma^2}{n}\right)
\]</span></p>
<ol start="2" type="a">
<li><p>When <span class="math inline">\(n\)</span> is small, the sample mean may not be approximately normally distributed. The CLT is an asymptotic result, so the normal approximation improves with larger <span class="math inline">\(n\)</span>. If the population distribution is skewed or heavy-tailed, then the distribution of <span class="math inline">\(\overline{X}_n\)</span> is typically <strong>farther</strong> from the asymptotic normal distribution.</p></li>
<li><p>The first thing we need to do for both problems is to recall how we’ve defined <span class="math display">\[\overline{X}_n\]</span>. By substituting and doing some algebra we will arrive at our desired results.</p></li>
<li><p><span class="math display">\[ E\left[\overline{X}_n\right]=E\left[\frac{1}{n}\sum^n_{i=1}X_i\right] \]</span></p></li>
</ol>
<p>For expected values we are allowed to move constants such as <span class="math inline">\(\frac{1}{n}\)</span> outside of our brackets. We also know that the sum of an expectation is the expectation of teh sum, meaning that we can move the sum outside of our brackets as well.</p>
<p><span class="math display">\[ E\left[\frac{1}{n}\sum^n_{i=1}X_i\right]=\frac{1}{n}\sum^n_{i=1}E \left[X_i \right] \]</span> Now we can take advantage of all <span class="math inline">\(X_i\)</span> being i.i.d., meaning they are identically distirbuted and will thus have the same mean, namely <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[ \frac{1}{n}\sum^n_{i=1}E \left[X_i \right]=\frac{1}{n}\sum^n_{i=1}\mu=\frac{n}{n}\mu=\mu\]</span> I.e.</p>
<p><span class="math display">\[E\left[\overline{X}_n\right]=\mu\]</span> ii) We essentially repeat the process here.</p>
<p><span class="math display">\[ Var \left[\overline{X}_n \right] = Var \left[\frac{1}{n}\sum^n_{i=1}X_i \right] \]</span> For variances we are allowed to move constants such as <span class="math inline">\(\frac{1}{n}\)</span> outside of our brackets if we <strong>square</strong> them. I.e.</p>
<p><span class="math display">\[Var[aY]=a^2Var[Y] \]</span> (For those not entirely convinced by this, try to compute it bye using that <span class="math inline">\(Var[Y]=E[Y^2]-(E[X])^2\)</span>)</p>
<p>We also have that the sum of a variance is the variance of the sum as long as the random variables included in the sum are mutually independent of each other. In this case all our variables are i.i.d., meaning that the independence requirement is met; and thus we can move the sum outside of the brackets as well. We then get:</p>
<p><span class="math display">\[ Var \left[\frac{1}{n}\sum^n_{i=1}X_i \right] = \frac{1}{n^2}\sum^n_{i=1}Var[X_i] \]</span></p>
<p>All of our <span class="math inline">\(X_i\)</span> are identically distributed with the same variance; <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[ \frac{1}{n^2}\sum^n_{i=1}Var[X_i] = \frac{1}{n^2}\sum^n_{i=1}\sigma^2=\frac{n}{n^2}\sigma^2=\frac{\sigma^2}{n} \]</span> And we are done</p>
<p><span class="math display">\[ Var \left[\overline{X}_n \right]=\frac{\sigma^2}{n} \]</span></p>
</details>
</section>
<section id="problem-19" class="level3">
<h3 class="anchored" data-anchor-id="problem-19">Problem 19</h3>
<p>You want to apply the Central Limit Theorem to a dataset of measurements collected from a machine. However, before proceeding, your colleague reminds you that “the CLT has assumptions!”</p>
<ol type="a">
<li><p>List the assumptions required for the CLT to hold for sample means.</p></li>
<li><p>Suppose the machine’s output is not independent from one sample to the next. Can you still apply the CLT?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>The main assumptions for the classical CLT are:</li>
</ol>
<ul>
<li>The data are <strong>independent</strong></li>
<li>The data are <strong>identically distributed</strong></li>
<li>The population has <strong>finite mean</strong> and <strong>finite variance</strong></li>
</ul>
<ol start="2" type="a">
<li>If the data are not independent (e.g., time-dependent or autocorrelated), then the classical CLT may not apply. There are generalized versions of the CLT for dependent data, but in this setting, using the standard version would lead to misleading conclusions about the sampling distribution.</li>
</ol>
</details>
</section>
<section id="problem-20" class="level3">
<h3 class="anchored" data-anchor-id="problem-20">Problem 20</h3>
<p>You simulate 10,000 observations from each of the following distributions:</p>
<ul>
<li>Exponential(1)</li>
<li>Uniform(0, 1)</li>
<li>Bernoulli(0.2)</li>
</ul>
<p>For each distribution, you compute the sample mean of many repeated samples of size <span class="math inline">\(n = 50\)</span>. What assumptions would you have to make in this case to be certain?</p>
<ol type="a">
<li><p>For each distribution above, is the CLT applicable? Why?</p></li>
<li><p>What would you expect the distribution of the sample means to look like?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Our requirements to use CLT are:</li>
</ol>
<ul>
<li>The distributions have finite mean and variance</li>
<li>We have a random sample of fixed size</li>
<li>The samples are independent and identically distributed</li>
</ul>
<p>In all cases we have that the distributions have finite means and variances. Since we’re simulating from the same distributions, we can be certain they are identical, but we still assume independence (using a random draw with Python for example this requirement is met). It’s also clear that we have random samples of a fixed size in this case as our simulation is takes the mean of assorted samples of 50.</p>
<ol start="2" type="a">
<li>In all three cases, the distribution of sample means should be approximately normal, centered at the true population mean, with smaller spread as <span class="math inline">\(n\)</span> increases. The exponential is heavily skewed, so its sample mean distribution may look less normal than the others, but should still be roughly bell-shaped.</li>
</ol>
</details>
</section>
<section id="problem-21" class="level3">
<h3 class="anchored" data-anchor-id="problem-21">Problem 21</h3>
<p>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be i.i.d. random variables from a distribution with mean <span class="math inline">\(\mu = 3\)</span> and variance <span class="math inline">\(\sigma^2 = 4\)</span>. You take a random sample of size <span class="math inline">\(n = 100\)</span>.</p>
<ol type="a">
<li><p>Use the CLT to approximate the distribution of the <strong>sample mean</strong> <span class="math inline">\(\overline{X}\)</span>.</p></li>
<li><p>Use the CLT to approximate the distribution of the <strong>sum</strong> <span class="math inline">\(S_n = \sum_{i=1}^n X_i\)</span>.</p></li>
</ol>
<p>Hint: <span class="math inline">\(S_n=n\overline{X}\)</span> which can be used for computation</p>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>By CLT:</li>
</ol>
<p><span class="math display">\[
\overline{X} \sim \mathcal{N}\left(3, \frac{4}{100}\right) = \mathcal{N}(3, 0.04)
\]</span></p>
<ol start="2" type="a">
<li>Since <span class="math inline">\(S_n = n\overline{X}\)</span>, and <span class="math inline">\(\overline{X} \sim \mathcal{N}(3, 0.04)\)</span>, then:</li>
</ol>
<p><span class="math display">\[
S_n \sim \mathcal{N}(300, 400)
\]</span> <span class="math display">\[E[S_n]=\cdots=\frac{n}{n}\sum^n_{i=1}\mu=100\mu=300 \\
Var[S_n]=\cdots=\frac{n^2}{n^2}\sum^n_{i=1}\sigma=100\sigma=400 \]</span></p>
<p><em>For those wanting an extra challenge, try finding a general rule for how the mean and variance of a normal distribution of a sum such this would scale by multiplying with a constant</em> <span class="math inline">\(a\)</span></p>
</details>
</section>
<section id="problem-22" class="level3">
<h3 class="anchored" data-anchor-id="problem-22">Problem 22</h3>
<p>You are studying the average number of daily steps taken by students at a university.</p>
<ol type="a">
<li><p>You collect a random sample of 100 students and calculate the mean number of steps. What is this quantity called?</p></li>
<li><p>Before collecting data, you write down the formula you plan to use to estimate the mean from any future sample. What is this formula called?</p></li>
<li><p>What is the term for the true, but unknown, average number of steps taken by all students at the university (for instance <span class="math inline">\(\theta\)</span>)?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>This is an <strong>estimate</strong> — a realized numerical value from a specific sample.</li>
<li>This is an <strong>estimator</strong> — a rule or formula for calculating an estimate.</li>
<li>This is the <strong>parameter</strong> — the true population quantity we aim to estimate.</li>
</ol>
</details>
</section>
<section id="problem-23" class="level3">
<h3 class="anchored" data-anchor-id="problem-23">Problem 23</h3>
<p>Let <span class="math inline">\(\hat{\theta}\)</span> be an estimator for a population parameter <span class="math inline">\(\theta\)</span>.</p>
<ol type="a">
<li><p>Define what it means for <span class="math inline">\(\hat{\theta}\)</span> to be an <strong>unbiased</strong> estimator of <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Define what it means for <span class="math inline">\(\hat{\theta}\)</span> to be a <strong>consistent</strong> estimator of <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Are these two properties related? Can an estimator be one but not the other?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>An estimator <span class="math inline">\(\hat{\theta}\)</span> is <strong>unbiased</strong> if <span class="math inline">\(E[\hat{\theta}] = \theta\)</span>.</p></li>
<li><p>An estimator is <strong>consistent</strong> if <span class="math inline">\(\hat{\theta} \to \theta\)</span> in probability as the sample size <span class="math inline">\(n \to \infty\)</span>. I.e. as the sample size <span class="math inline">\(n\)</span> increases, the estimator <span class="math inline">\(\hat{\theta}\)</span> will approach the true paramter value <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Yes, they are distinct properties. An estimator can be:</p></li>
</ol>
<ul>
<li>Unbiased but not consistent (e.g., large variance that doesn’t shrink with <span class="math inline">\(n\)</span>).</li>
<li>Biased but consistent (e.g., estimators that converge with increasing <span class="math inline">\(n\)</span>, even if not centered).</li>
</ul>
</details>
</section>
<section id="problem-24" class="level3">
<h3 class="anchored" data-anchor-id="problem-24">Problem 24</h3>
<p>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be iid with man <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Consider the sample variance:</p>
<p><span class="math display">\[
S_n^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2
\]</span></p>
<ol type="a">
<li><p>Is <span class="math inline">\(S_n^2\)</span> an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>? Explain.</p></li>
<li><p>Suggest an adjusted estimator that is unbiased, and write the formula.</p></li>
<li><p>Given that <span class="math display">\[E\left[\sum^n_{i=1}(X_i-\overline{X})^2\right]=(n-1)\sigma^2 \]</span> Use this to show that the sample variance <span class="math inline">\(S^2\)</span> is an unbiased estimator for <span class="math inline">\(\sigma^2\)</span>.</p></li>
</ol>
<p>When</p>
<p><span class="math display">\[S^2=\frac{1}{n-1}\sum^n_{i=1}(X_i-\overline{X})^2\]</span></p>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>No, <span class="math inline">\(S_n^2\)</span> is biased. Its expected value is slightly less than <span class="math inline">\(\sigma^2\)</span>, especially for small <span class="math inline">\(n\)</span>. This is due to the fact that <span class="math inline">\(\bar{X}\)</span> is estimated from the same data and introduces extra variability.</p></li>
<li><p>The <strong>unbiased estimator</strong> of variance is:</p></li>
</ol>
<p><span class="math display">\[
S^2 = \frac{1}{n - 1} \sum_{i=1}^n (X_i - \overline{X})^2
\]</span> c)</p>
<p>Using the provided identity:</p>
<p><span class="math display">\[
E[S^2] = E\left[\frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2\right] = \frac{1}{n-1} \cdot (n - 1)\sigma^2 = \sigma^2
\]</span></p>
<p>So <span class="math inline">\(S^2\)</span> is <strong>unbiased</strong>.</p>
</details>
</section>
<section id="problem-25" class="level3">
<h3 class="anchored" data-anchor-id="problem-25">Problem 25</h3>
<p>Suppose you are comparing two estimators of a parameter <span class="math inline">\(\theta\)</span>:</p>
<ul>
<li>Estimator A is <strong>unbiased</strong>, but has high variance.</li>
<li>Estimator B is <strong>biased</strong>, but the bias gets smaller as the sample size grows, and the variance is low.</li>
</ul>
<ol type="a">
<li><p>Which estimator would you prefer if you care about consistency?</p></li>
<li><p>Which estimator would you prefer if you care most about low error in small samples?</p></li>
<li><p>Can Estimator B be consistent, even though it is biased?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>Estimator B is preferable if it is <strong>consistent</strong>, because consistency ensures convergence to the true value as <span class="math inline">\(n \to \infty\)</span>.</p></li>
<li><p>In small samples, Estimator A may perform poorly due to high variance. Estimator B may be preferred due to lower overall error.</p></li>
<li><p>Yes — <strong>bias and consistency are not mutually exclusive</strong>. Estimator B can be biased but consistent if the bias vanishes as <span class="math inline">\(n \to \infty\)</span>.</p></li>
</ol>
</details>
</section>
<section id="problem-26" class="level3">
<h3 class="anchored" data-anchor-id="problem-26">Problem 26</h3>
<p>Consider the properties of the sample mean <span class="math inline">\(\overline{X}\)</span> and sample variance <span class="math inline">\(S^2\)</span> as estimators.</p>
<ol type="a">
<li><p>Are both unbiased? Under what conditions?</p></li>
<li><p>Are both consistent?</p></li>
<li><p>What happens to these properties when data are not iid?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p><span class="math inline">\(\overline{X}\)</span> is always unbiased for <span class="math inline">\(\mu\)</span> if the mean exists. <span class="math inline">\(S^2\)</span> is unbiased for <span class="math inline">\(\sigma^2\)</span> <strong>if</strong> the data are iid and <span class="math inline">\(\sigma^2\)</span> exists.</p></li>
<li><p>Both are <strong>consistent</strong> if the data are iid and the mean and variance exist (mean for <span class="math inline">\(\overline{X}\)</span>, variance for <span class="math inline">\(S^2\)</span>).</p></li>
<li><p>If data are <strong>not iid</strong>:</p></li>
</ol>
<ul>
<li>Bias may be introduced (e.g., if dependent observations).</li>
<li>Consistency may fail if dependence inflates variance or reduces effective sample size.</li>
</ul>
</details>
</section>
<section id="problem-27" class="level3">
<h3 class="anchored" data-anchor-id="problem-27">Problem 27</h3>
<p>Suppose you observe independent data points <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> drawn from a distribution with a density <span class="math inline">\(f(x; \theta)\)</span>, where <span class="math inline">\(\theta\)</span> is an unknown parameter.</p>
<ol type="a">
<li><p>Define the likelihood function <span class="math inline">\(L(\theta)\)</span> based on this data.</p></li>
<li><p>Explain why, when maximizing the likelihood, we often instead maximize the log-likelihood.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>The likelihood is the joint probability (or density) of the observed data, viewed as a function of <span class="math inline">\(\theta\)</span>:</li>
</ol>
<p><span class="math display">\[
L(\theta) = \prod_{i=1}^n f(X_i; \theta)
\]</span></p>
<ol start="2" type="a">
<li>We often maximize the log-likelihood because:</li>
</ol>
<ul>
<li>It turns a product into a sum: <span class="math inline">\(\log L(\theta) = \sum_{i=1}^n \log f(X_i; \theta)\)</span></li>
<li>It’s easier to differentiate and solve</li>
<li>It avoids numerical issues caused by multiplying many small probabilities</li>
</ul>
</details>
</section>
<section id="problem-28" class="level3">
<h3 class="anchored" data-anchor-id="problem-28">Problem 28</h3>
<p>Let <span class="math inline">\(X_1, \dots, X_n \sim \text{iid Geometric}(p)\)</span>, where <span class="math inline">\(p \in (0,1)\)</span> is the probability of success. The pmf is:</p>
<p><span class="math display">\[
P(X = k) = (1 - p)^{k - 1} p, \quad k = 1, 2, 3, \dots
\]</span></p>
<ol type="a">
<li><p>Write the log-likelihood function for the observed sample.</p></li>
<li><p>Derive the maximum likelihood estimator <span class="math inline">\(\hat{p}\)</span>.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li></li>
</ol>
<p><span class="math display">\[
L(p) = \prod_{i=1}^n (1 - p)^{X_i - 1} p = (1 - p)^{\sum (X_i - 1)} p^n
\]</span></p>
<p><span class="math display">\[
\Rightarrow \ell(p) = \log L(p) = (n \log p) + \left( \sum^n_{i=1} (X_i - 1) \right) \log(1 - p)
= n \log p + (n \bar{X} - n) \log(1 - p)
\]</span></p>
<ol start="2" type="a">
<li>Differentiate:</li>
</ol>
<p><span class="math display">\[
\frac{d\ell}{dp} = \frac{n}{p} - \frac{n \bar{X} - n}{1 - p}
\Rightarrow \frac{1}{p} = \frac{\bar{X} - 1}{1 - p}
\Rightarrow \hat{p} = \frac{1}{\bar{X}}
\]</span></p>
<p>So, the MLE is <span class="math inline">\(\hat{p} = \dfrac{1}{\overline{X}}\)</span>.</p>
</details>
</section>
<section id="problem-29" class="level3">
<h3 class="anchored" data-anchor-id="problem-29">Problem 29</h3>
<p>Suppose you observe <span class="math inline">\(X_1, \dots, X_n \sim f(x; \theta)\)</span>, where <span class="math inline">\(f(x; \theta)\)</span> is a known family of distributions.</p>
<ol type="a">
<li><p>Why must the data be for the data to be iid when using MLE?</p></li>
<li><p>What could go wrong if the data are not iid?</p></li>
<li><p>Suppose the true distribution of the data is not in the family <span class="math inline">\(f(x; \theta)\)</span>. What consequences might this have?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>If the data are iid:</li>
</ol>
<ul>
<li>The joint probability factorizes nicely as it will be a product of identical identities</li>
<li>The likelihood simplifies</li>
<li>The MLE behaves well and has known properties (e.g.&nbsp;consistency)</li>
</ul>
<ol start="2" type="a">
<li>If data are not iid:</li>
</ol>
<ul>
<li>The likelihood expression is invalid or more complicated</li>
<li>The MLE may be <strong>biased</strong> or <strong>inconsistent</strong></li>
<li>Inference based on the MLE may be misleading</li>
</ul>
<ol start="3" type="a">
<li>If the model is wrong (i.e., the true distribution isn’t in the family):</li>
</ol>
<ul>
<li>The MLE still finds the “best-fitting” parameter within the family, but it’s not estimating the <strong>true</strong> parameter</li>
<li>This is called <strong>model misspecification</strong></li>
<li>The MLE may converge to a value that minimizes some distance, but it’s not consistent for the true data-generating parameter</li>
</ul>
</details>
</section>
<section id="problem-30" class="level3">
<h3 class="anchored" data-anchor-id="problem-30">Problem 30</h3>
<p>Let <span class="math inline">\(U \sim \text{Uniform}(0,1)\)</span>. You are told that it is possible to generate a random variable <span class="math inline">\(X\)</span> from another distribution by transforming <span class="math inline">\(U\)</span>. This technique is called <strong>inverse transform sampling</strong>.</p>
<p>Suppose you want to generate random variables from an exponential distribution with parameter <span class="math inline">\(\lambda &gt; 0\)</span>, which has CDF</p>
<p><span class="math display">\[
F(x) = 1 - e^{-\lambda x}, \quad x \ge 0
\]</span></p>
<ol type="a">
<li><p>Solve for the inverse of the CDF, <span class="math inline">\(F^{-1}(u)\)</span>, where <span class="math inline">\(u \in (0,1)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(U \sim \text{Uniform}(0,1)\)</span>. Show that if we define <span class="math inline">\(X = F^{-1}(U)\)</span>, then <span class="math inline">\(X \sim \text{Exp}(\lambda)\)</span>.</p></li>
<li><p>What general steps does this illustrate about how inverse transform sampling works?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Start with:</li>
</ol>
<p><span class="math display">\[
F(x) = 1 - e^{-\lambda x}
\Rightarrow u = 1 - e^{-\lambda x}
\Rightarrow e^{-\lambda x} = 1 - u
\Rightarrow -\lambda x = \log(1 - u)
\Rightarrow x = -\frac{1}{\lambda} \log(1 - u)
\]</span></p>
<p>Since <span class="math inline">\(1 - u \sim \text{Uniform}(0,1)\)</span> as well, we often write:</p>
<p><span class="math display">\[
F^{-1}(u) = -\frac{1}{\lambda} \log u
\]</span></p>
<ol start="2" type="a">
<li>Let <span class="math inline">\(U \sim \text{Uniform}(0,1)\)</span> and define <span class="math inline">\(X = -\frac{1}{\lambda} \log U\)</span>. We want to show that <span class="math inline">\(X \sim \text{Exp}(\lambda)\)</span>. Compute the CDF:</li>
</ol>
<p><span class="math display">\[
P(X \le x) = P\left(-\frac{1}{\lambda} \log U \le x\right) = P\left(\log U \ge -\lambda x\right)
= P\left(U \ge e^{-\lambda x}\right)
= 1 - P(U &lt; e^{-\lambda x}) = 1 - e^{-\lambda x}
\]</span> For the last step you must recall the CDF of a uniform distribution.<span class="math display">\[U\sim \text{Uniform(a,b)}\]</span>. In our case we have <span class="math inline">\(a=0\)</span> and <span class="math inline">\(b=1\)</span>.</p>
<p><span class="math display">\[F_U(u)=P(U\leq u)=\frac{u}{b-a}=\frac{u}{1}=u\]</span></p>
<p>So the CDF of <span class="math inline">\(X\)</span> matches the exponential distribution. Hence, <span class="math inline">\(X \sim \text{Exp}(\lambda)\)</span>.</p>
<ol start="3" type="a">
<li>The <strong>inverse transform sampling procedure</strong> works as follows:</li>
</ol>
<!-- -->
<ol type="1">
<li>Start with a known distribution with invertible CDF, <span class="math inline">\(F\)</span></li>
<li>Sample <span class="math inline">\(U \sim \text{Uniform}(0,1)\)</span></li>
<li>Set <span class="math inline">\(X = F^{-1}(U)\)</span></li>
</ol>
<p>Then <span class="math inline">\(X\)</span> has the distribution defined by <span class="math inline">\(F\)</span>. This method is particularly useful when direct sampling is hard, but the inverse CDF is known or easy to compute.</p>
</details>
</section>
<section id="problem-31" class="level3">
<h3 class="anchored" data-anchor-id="problem-31">Problem 31</h3>
<p>In this exercise, you will implement inverse transform sampling to generate samples from an exponential distribution with rate <span class="math inline">\(\lambda = 2\)</span>, and compare the result to samples generated by R’s built-in exponential sampler. (Feel free to use Python or any other language to do the same)</p>
<ol type="a">
<li>Use the inverse CDF method to generate 10,000 samples from an <span class="math inline">\(\text{Exp}(\lambda = 2)\)</span> distribution in R. Recall the inverse CDF is</li>
</ol>
<p><span class="math display">\[
X = -\frac{1}{\lambda} \log(U)
\]</span></p>
<ol start="2" type="a">
<li><p>Use R’s built-in function <code>rexp(n, rate = 2)</code> to generate another 10,000 samples from the same distribution.</p></li>
<li><p>Create a histogram of both sample sets on the same scale. Overlay the theoretical exponential density curve for comparison.</p></li>
<li><p>Comment on the similarity between the two sample sets and the theoretical distribution. What does this illustrate about inverse transform sampling?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Generate using inverse CDF:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>lambda_ <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate uniform random numbers</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Inverse transform sampling</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>x_inv <span class="op">=</span> <span class="op">-</span>np.log(u) <span class="op">/</span> lambda_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="2" type="a">
<li>Generate using built-in function:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x_builtin <span class="op">=</span> np.random.exponential(scale<span class="op">=</span><span class="dv">1</span><span class="op">/</span>lambda_, size<span class="op">=</span>n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ol start="3" type="a">
<li>Plot histo}grams with density curve:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histogram for inverse transform samples</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.hist(x_inv, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.5</span>), <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">4</span>),</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Inverse CDF'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)<span class="op">;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Overlay histogram for built-in samples</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.hist(x_builtin, bins<span class="op">=</span><span class="dv">50</span>, density<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.5</span>), <span class="bu">range</span><span class="op">=</span>(<span class="dv">0</span>, <span class="dv">4</span>),</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>         label<span class="op">=</span><span class="st">'Built-in'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)<span class="op">;</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Theoretical density curve</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>x_vals <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">500</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>y_vals <span class="op">=</span> lambda_ <span class="op">*</span> np.exp(<span class="op">-</span>lambda_ <span class="op">*</span> x_vals)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.plot(x_vals, y_vals, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Theoretical Density'</span>)<span class="op">;</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Labels and legend</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Inverse Transform vs Built-in Sampling"</span>)<span class="op">;</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"x"</span>)<span class="op">;</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)<span class="op">;</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="dv">2</span>)<span class="op">;</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'upper right'</span>)<span class="op">;</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="3-exercises_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<ol start="4" type="a">
<li>The histograms of both sample sets are visually indistinguishable and both closely match the theoretical density curve of the exponential distribution. This illustrates that inverse transform sampling correctly reproduces the distribution, even when sampling is done indirectly via uniform draws.</li>
</ol>
</details>
</section>
<section id="problem-32" class="level3">
<h3 class="anchored" data-anchor-id="problem-32">Problem 32</h3>
<p>Monte Carlo simulation is a technique used to approximate mathematical quantities through repeated random sampling.</p>
<ol type="a">
<li><p>What is the purpose of Monte Carlo simulation in statistics and data analysis?</p></li>
<li><p>How does the Law of Large Numbers justify the use of Monte Carlo methods?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>Monte Carlo simulation is used to estimate expectations, probabilities, or other quantities that are hard (or impossible) to compute analytically. By simulating many random samples and averaging the results, we approximate the desired value.</p></li>
<li><p>The Law of Large Numbers states that the sample average converges to the expected value as the number of samples increases. In Monte Carlo methods, this justifies approximating:</p></li>
</ol>
<p><span class="math display">\[
E[f(X)] \approx \frac{1}{n} \sum_{i=1}^n f(X_i)
\]</span></p>
<p>where <span class="math inline">\(X_i \sim \text{Distribution of } X\)</span>.</p>
</details>
</section>
<section id="problem-33" class="level3">
<h3 class="anchored" data-anchor-id="problem-33">Problem 33</h3>
<p>Let <span class="math inline">\(X \sim \text{Uniform}(0, 1)\)</span>. You are interested in estimating <span class="math inline">\(E[X^2]\)</span> using Monte Carlo simulation.</p>
<ol type="a">
<li><p>Generate three values: <span class="math inline">\(X_1 = 0.2, X_2 = 0.6, X_3 = 0.9\)</span>. Use these to compute a Monte Carlo estimate of <span class="math inline">\(E[X^2]\)</span>.</p></li>
<li><p>Compute the exact expected value of <span class="math inline">\(X^2\)</span> when <span class="math inline">\(X \sim \text{Uniform}(0, 1)\)</span>, and compare.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Estimate:</li>
</ol>
<p><span class="math display">\[
E[X^2] \approx \frac{1}{3}(0.2^2 + 0.6^2 + 0.9^2) = \frac{1}{3}(0.04 + 0.36 + 0.81) = \frac{1.21}{3} \approx 0.403
\]</span></p>
<ol start="2" type="a">
<li>To compute <span class="math inline">\(E[X^2]\)</span> exactly, recall that for a continuous distribution like <span class="math inline">\(\text{Uniform}(0,1)\)</span>, we define <span class="math inline">\(E[g(X)]\)</span>, where <span class="math inline">\(g(X)\)</span> is some function of the random variable <span class="math inline">\(X\)</span>, as</li>
</ol>
<p><span class="math display">\[ \int^\infty_{-\infty}g(x)f(x)dx \]</span> Where <span class="math inline">\(f(x)\)</span> is the probility density function of the random variable <span class="math inline">\(X\)</span>.</p>
<p>For our distribution in this case <span class="math inline">\(g(x)=x^2\)</span>, and since it’s uniform on the support <span class="math inline">\((0,1)\)</span>, the pdf if given by:</p>
<p><span class="math display">\[f(x)= \begin{cases}
  1, \quad for \ x\in(0,1) \\
  0, \quad other  
\end{cases} \]</span></p>
<p>Now we can use this to compute the exact value. Exact value:</p>
<p><span class="math display">\[
E[X^2] = \int_0^1 x^2 dx =\frac{1}{3}\left[x^3\right]^1_0= \frac{1}{3} \approx 0.333
\]</span></p>
<p>The estimate <span class="math inline">\(0.403\)</span> is fairly close given the very small sample size.</p>
</details>
</section>
<section id="problem-34" class="level3">
<h3 class="anchored" data-anchor-id="problem-34">Problem 34</h3>
<p>You want to estimate the area under the curve <span class="math inline">\(y = \sqrt{1 - x^2}\)</span> for <span class="math inline">\(x \in [0,1]\)</span>, which corresponds to a quarter of a unit circle. This will allow you to approximate <span class="math inline">\(\pi\)</span>.</p>
<ol type="a">
<li><p>Explain how you can estimate this area using Monte Carlo simulation.</p></li>
<li><p>Without using a computer, simulate with the following 5 random pairs:</p></li>
</ol>
<p><span class="math display">\[
(x, y) \in \{ (0.1, 0.5), (0.4, 0.2), (0.6, 0.9), (0.3, 0.7), (0.9, 0.1) \}
\]</span></p>
<p>Use these to estimate the area.</p>
<ol start="3" type="a">
<li>What is the true area? How good is the estimate?</li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>We sample points <span class="math inline">\((x, y)\)</span> uniformly in the unit square <span class="math inline">\([0,1] \times [0,1]\)</span>, and count how many fall below the curve. The proportion of points under the curve estimates the area.</p></li>
<li><p>We check whether each point satisfies <span class="math inline">\(y \le \sqrt{1 - x^2}\)</span>, as only those will fall withing the quarter of the unit circle:</p></li>
</ol>
<ul>
<li><span class="math inline">\((0.1, 0.5)\)</span>: <span class="math inline">\(\sqrt{1 - 0.01} = \sqrt{0.99} \approx 0.995 &gt; 0.5\)</span>: ✅</li>
<li><span class="math inline">\((0.4, 0.2)\)</span>: <span class="math inline">\(\sqrt{1 - 0.16} = \sqrt{0.84} \approx 0.916 &gt; 0.2\)</span>: ✅</li>
<li><span class="math inline">\((0.6, 0.9)\)</span>: <span class="math inline">\(\sqrt{1 - 0.36} = \sqrt{0.64} = 0.8 &lt; 0.9\)</span>: ❌</li>
<li><span class="math inline">\((0.3, 0.7)\)</span>: <span class="math inline">\(\sqrt{1 - 0.09} = \sqrt{0.91} \approx 0.954 &gt; 0.7\)</span>: ✅</li>
<li><span class="math inline">\((0.9, 0.1)\)</span>: <span class="math inline">\(\sqrt{1 - 0.81} = \sqrt{0.19} \approx 0.436 &gt; 0.1\)</span>: ✅</li>
</ul>
<p>So, 4 out of 5 points were below the curve:</p>
<p><span class="math display">\[
\text{Estimated area} = \frac{4}{5} = 0.8
\]</span> We know the area of the unit circle is <span class="math inline">\(\pi\)</span>, so the quarter we’ve estimated now should be a <strong>fourth</strong> of <span class="math inline">\(\pi\)</span>. As such we get:</p>
<p><span class="math display">\[\text{Estimated } \pi = 4 \times 0.8 = 3.2\]</span></p>
<ol start="3" type="a">
<li>The true area is <span class="math inline">\(\frac{\pi}{4} \Rightarrow \pi \approx 3.14\)</span>. Our estimate of 3.2 is quite reasonable for only 5 points!</li>
</ol>
</details>
</section>
<section id="problem-35" class="level3">
<h3 class="anchored" data-anchor-id="problem-35">Problem 35</h3>
<p>Use Monte Carlo simulation to estimate the integral:</p>
<p><span class="math display">\[
\int_0^1 \frac{1}{1 + x^2} dx
\]</span></p>
<p>This integral equals <span class="math inline">\(\arctan(1) = \frac{\pi}{4}\)</span>. You should use Python to approximate this value.</p>
<ol type="a">
<li><p>Write python code to generate 100,000 samples <span class="math inline">\(X_i \sim \text{Uniform}(0, 1)\)</span>, and compute <span class="math inline">\(\frac{1}{100{,}000} \sum \frac{1}{1 + X_i^2}\)</span>.</p></li>
<li><p>Compare your result to the true value <span class="math inline">\(\frac{\pi}{4}\)</span>.</p></li>
<li><p>How would increasing the number of samples affect the estimate?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Python code:</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100000</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.random.uniform(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Monte Carlo estimate</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>estimate <span class="op">=</span> np.mean(<span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> x<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(estimate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.7852382622958511</code></pre>
</div>
</div>
<ol start="2" type="a">
<li></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>true_value <span class="op">=</span> np.pi <span class="op">/</span> <span class="dv">4</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>abs_error <span class="op">=</span> <span class="bu">abs</span>(estimate <span class="op">-</span> true_value)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(true_value, abs_error)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.7853981633974483 0.00015990110159713744</code></pre>
</div>
</div>
<p>Output is typically very close, e.g., around <code>0.7854</code>.</p>
<ol start="3" type="a">
<li>As the number of samples increases, the estimate becomes more accurate and more stable, thanks to the Law of Large Numbers. The standard error of the mean decreases like <span class="math inline">\(1/\sqrt{n}\)</span>.</li>
</ol>
</details>
</section>
<section id="problem-36" class="level3">
<h3 class="anchored" data-anchor-id="problem-36">Problem 36</h3>
<p>Suppose you observe the following dataset of 5 values:</p>
<p><span class="math display">\[
\{4.1,\ 5.3,\ 2.8,\ 6.0,\ 3.9\}
\]</span></p>
<ol type="a">
<li><p>What is meant by a bootstrap sample? How is it created?</p></li>
<li><p>Generate two bootstrap samples from the dataset above by sampling <strong>with replacement</strong>.</p></li>
<li><p>Why is it important that bootstrap sampling is done with replacement?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>A bootstrap sample is a new sample of the same size drawn <em>with replacement</em> from the original data. It mimics the idea of repeated sampling from the population by reusing the observed data.</p></li>
<li><p>Example bootstrap samples:</p></li>
</ol>
<ul>
<li>Sample 1: {5.3, 2.8, 4.1, 4.1, 3.9}</li>
<li>Sample 2: {6.0, 3.9, 5.3, 6.0, 2.8}</li>
</ul>
<p>(Answers may vary depending on random sampling.)</p>
<ol start="3" type="a">
<li>Sampling <strong>with replacement</strong> is crucial in bootstrap methods because we only have one sample from the population. Replacement introduces variability and simulates the act of drawing new samples from the population.</li>
</ol>
</details>
</section>
<section id="problem-37" class="level3">
<h3 class="anchored" data-anchor-id="problem-37">Problem 37</h3>
<p>Let <span class="math inline">\(\hat{\theta} = \overline{X}\)</span> be the estimator of the mean from the original sample:</p>
<p><span class="math display">\[
\{2.0,\ 4.0,\ 6.0,\ 8.0\}
\]</span></p>
<p>Suppose you compute the means of three bootstrap samples (each of size 4 with replacement):</p>
<ul>
<li>Sample 1 mean: 4.5</li>
<li>Sample 2 mean: 5.0</li>
<li>Sample 3 mean: 3.5</li>
</ul>
<ol type="a">
<li><p>What is the original estimate <span class="math inline">\(\hat{\theta}\)</span>?</p></li>
<li><p>What is the bootstrap estimate of the bias?</p></li>
<li><p>What is the bias-corrected estimate?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Original estimate:</li>
</ol>
<p><span class="math display">\[
\hat{\theta} = \frac{2 + 4 + 6 + 8}{4} = 5
\]</span></p>
<ol start="2" type="a">
<li>Bootstrap mean estimate:</li>
</ol>
<p><span class="math display">\[
\hat{\theta}^* = \frac{4.5 + 5.0 + 3.5}{3} = 4.33\ldots
\]</span></p>
<p>Bias estimate:</p>
<p><span class="math display">\[
\text{Bias} = \hat{\theta}^* - \hat{\theta} = 4.33 - 5 = -0.67
\]</span></p>
<ol start="3" type="a">
<li>Bias-corrected estimate:</li>
</ol>
<p><span class="math display">\[
\hat{\theta}_{\text{corr}} = \hat{\theta} - \text{Bias} = 5 - (-0.67) = 5.67
\]</span></p>
</details>
</section>
<section id="problem-38" class="level3">
<h3 class="anchored" data-anchor-id="problem-38">Problem 38</h3>
<p>Suppose you have the following data that you believe follows a Poisson distribution:</p>
<p><span class="math display">\[
\{2,\ 1,\ 0,\ 3,\ 2,\ 1,\ 4\}
\]</span></p>
<ol type="a">
<li><p>Describe how you would perform a <strong>nonparametric bootstrap</strong> to estimate the sampling distribution of the sample mean.</p></li>
<li><p>Describe how you would perform a <strong>parametric bootstrap</strong> in this case.</p></li>
<li><p>Why might the parametric bootstrap be more appropriate here?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Nonparametric bootstrap:</li>
</ol>
<!-- -->
<ol type="1">
<li>Resample (with replacement) from the data to create many new samples.</li>
<li>Compute the sample mean for each resample.</li>
<li>Use the distribution of means to estimate uncertainty.</li>
</ol>
<!-- -->
<ol start="2" type="a">
<li>Parametric bootstrap:</li>
</ol>
<!-- -->
<ol type="1">
<li>Estimate the parameter of the assumed model: <span class="math inline">\(\hat{\lambda} = \text{mean of the data} = \frac{2+1+0+3+2+1+4}{7} = 1.86\)</span></li>
<li>Generate new samples from <span class="math inline">\(\text{Poisson}(\hat{\lambda})\)</span> of size 7.</li>
<li>Repeat and compute the sample mean for each.</li>
<li>Analyze the distribution of those means.</li>
</ol>
<!-- -->
<ol start="3" type="a">
<li>If we believe the data is truly Poisson-distributed, the parametric bootstrap can capture the shape of the population better than the finite empirical distribution, especially with small sample sizes.</li>
</ol>
</details>
</section>
<section id="problem-39" class="level3">
<h3 class="anchored" data-anchor-id="problem-39">Problem 39</h3>
<p>Consider the dataset:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="fl">2.3</span>, <span class="fl">1.9</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>, <span class="fl">3.5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You are interested in the <strong>standard error of the median</strong>.</p>
<ol type="a">
<li><p>Use Pyhon to create 1,000 bootstrap samples of the same size and compute the median for each.</p></li>
<li><p>Use the bootstrap medians to estimate the standard error.</p></li>
<li><p>Plot the bootstrap distribution of the median.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Original data</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.array([<span class="fl">2.3</span>, <span class="fl">1.9</span>, <span class="fl">3.1</span>, <span class="fl">2.8</span>, <span class="fl">3.5</span>])</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>boot_medians <span class="op">=</span> np.empty(B)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap loop</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(B):</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    sample_i <span class="op">=</span> np.random.choice(data, size<span class="op">=</span>n, replace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    boot_medians[i] <span class="op">=</span> np.median(sample_i)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard error of the median</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>se_median <span class="op">=</span> np.std(boot_medians)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>plt.hist(boot_medians, bins<span class="op">=</span><span class="dv">20</span>, density<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">'skyblue'</span>, edgecolor<span class="op">=</span><span class="st">'black'</span>)<span class="op">;</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Bootstrap Distribution of Median"</span>)<span class="op">;</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Median"</span>)<span class="op">;</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Density"</span>)<span class="op">;</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()<span class="op">;</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="3-exercises_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(se_median)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.39077603560095653</code></pre>
</div>
</div>
<p>This gives an estimate of the sampling variability of the median using only the observed data.</p>
</details>
</section>
<section id="problem-40" class="level3">
<h3 class="anchored" data-anchor-id="problem-40">Problem 40</h3>
<p>The diameter of a randomly selected mechanical nut is a random variable with mean 10 mm and standard deviation 0.04 mm.</p>
<ol type="a">
<li><p>If <span class="math inline">\(\bar X\)</span> is the sample mean diameter of a random sample of <span class="math inline">\(n=16\)</span> nuts, where is the sampling distribution of <span class="math inline">\(\bar X\)</span> centered, and what is the standard deviation of the <span class="math inline">\(\bar X\)</span> distribution?</p></li>
<li><p>Answer the question in (a) for a sample size of <span class="math inline">\(n=64\)</span> nuts.</p></li>
<li><p>For which of the two random samples from (a) or (b), is <span class="math inline">\(\bar X\)</span> more likely to be within 0.01 mm from 10 mm? Explain your reasoning.</p></li>
</ol>
<p>Suppose the distrution of the diameter is normal.</p>
<ol start="5" type="a">
<li><p>Calculate <span class="math inline">\(P(9.99\le \bar X \le 10.01)\)</span> when <span class="math inline">\(n=16\)</span>.</p></li>
<li><p>How likely is it that the sample mean diameter exceeds 10.01 when <span class="math inline">\(n=25\)</span>.</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>Centered at 10 with standard deviation <span class="math inline">\(\sigma/\sqrt{n}=0.04/\sqrt{16}= 0.01\)</span>.</p></li>
<li><p>Centered at 10 with standard deviation <span class="math inline">\(\sigma/\sqrt{n}=0.04/\sqrt{64}= 0.005\)</span>.</p></li>
<li><p>With less variability, the second sample is more closely centered near 10.</p></li>
<li><p><span class="math inline">\(P(9.99\le \bar X \le 10.01)=P(\bar X \le 10.01)-P(\bar X \le 9.99) = 0.84-0.16= 0.68\)</span>, getting the numbers from the code below:</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  stats.norm.cdf(<span class="fl">10.01</span>, loc <span class="op">=</span> <span class="dv">10</span>, scale <span class="op">=</span> <span class="fl">0.04</span><span class="op">/</span>np.sqrt(<span class="dv">16</span>))<span class="op">-</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  stats.norm.cdf(<span class="fl">9.99</span>, loc <span class="op">=</span> <span class="dv">10</span>, scale <span class="op">=</span> <span class="fl">0.04</span><span class="op">/</span>np.sqrt(<span class="dv">16</span>))</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6826894921370756</code></pre>
</div>
</div>
<ol start="5" type="a">
<li><span class="math inline">\(P(\bar X_{25}&gt;10.01)=0.106\)</span>.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span><span class="op">-</span>stats.norm.cdf(<span class="fl">10.01</span>, loc <span class="op">=</span> <span class="dv">10</span>, scale <span class="op">=</span> <span class="fl">0.04</span><span class="op">/</span>np.sqrt(<span class="dv">25</span>))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.10564977366686001</code></pre>
</div>
</div>
</details>
</section>
<section id="problem-41" class="level3">
<h3 class="anchored" data-anchor-id="problem-41">Problem 41</h3>
<p>The tip percentage at a restaurant has a mean value of 18% and standard deviation of 6%.</p>
<ol type="a">
<li><p>What is the apporixmate probability that the sample mean tip percentage for a random sample of 40 bills is between 16% and 19%?</p></li>
<li><p>If the sample size had been rather 15 than 40, could the probability requested in part (a) be calculated from the given information?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>With <span class="math inline">\(n=40\)</span> observations, we can approximate the probability using the central limit theorem (CLT). That is <span class="math inline">\(\bar X_{40}\sim N(0.18, 0.06/\sqrt{40})\)</span>: <span class="math display">\[P(16\%\le \bar X_{40}\le 19\%)=P(\bar X_{40}\le 19\%)-P(\bar X_{40}\le 16\%)=0.8366\]</span></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="fl">0.18</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span> <span class="fl">0.06</span><span class="op">/</span>np.sqrt(<span class="dv">40</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.norm.cdf(<span class="fl">0.19</span>, loc<span class="op">=</span>mean, scale <span class="op">=</span>sd)<span class="op">-</span>stats.norm.cdf(<span class="fl">0.16</span>, loc<span class="op">=</span>mean, scale <span class="op">=</span> sd))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8365722369182748</code></pre>
</div>
</div>
<ol start="2" type="a">
<li>In (a) we used the Central Limit Theorem (CLT) to approximate the probability using a normal distribution. This relies on a large enough sample size. With only <span class="math inline">\(n=15\)</span> observations, the sample size is likely too low for the CLT. If we use it anyway, we get 0.6423 for the probability.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="fl">0.18</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span> <span class="fl">0.06</span><span class="op">/</span>np.sqrt(<span class="dv">15</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(stats.norm.cdf(<span class="fl">0.19</span>, loc<span class="op">=</span>mean, scale <span class="op">=</span>sd)<span class="op">-</span>stats.norm.cdf(<span class="fl">0.16</span>, loc<span class="op">=</span>mean, scale <span class="op">=</span> sd))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.6423446905561638</code></pre>
</div>
</div>
</details>
</section>
<section id="problem-42" class="level3">
<h3 class="anchored" data-anchor-id="problem-42">Problem 42</h3>
<p>Suppose the sugar content (g per cm³) of a randomly selected fruit from a certain orchard is normally distributed with a mean of 2.65 and a standard deviation of 0.85.</p>
<ol type="a">
<li><p>If a random sample of 25 fruits is selected, what is the probability that the sample average sugar content is at most 3.00? Between 2.65 and 3.00?</p></li>
<li><p>How large a sample size would be required to ensure that the first probability in part (a) is at least 0.99?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li>Let <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,\ldots, 25\)</span> denote the sugar content of 25 randomly selected fruits. We then have from the CLT that <span class="math inline">\(\overline X_{25}=\frac{1}{25}\sum_{i=1}^{25}X_i\)</span> is approximately <span class="math inline">\(N(\mu,\sigma^2/n)=N(2.65, 0.85^2/25)\)</span>.</li>
</ol>
<p>We can thus find the probabilities by</p>
<p><span class="math display">\[P(\overline X_{25} \le 3) = P\left(\frac{\overline X_{25}-\mu}{\sigma/\sqrt{n}}\le\frac{3-2.65}{0.85/\sqrt{25}}\right)=P(Z\le 2.059)=0.9802,\]</span> where the latter equality comes from</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(norm.cdf(<span class="fl">2.059</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9802528807563333</code></pre>
</div>
</div>
<p><span class="math display">\[P(\overline X_{25} \le 2.65) = P\left(\frac{\overline X_{25}-\mu}{\sigma/\sqrt{n}}\le\frac{2.65-2.65}{0.85/\sqrt{25}}\right)=P(Z\le 0)=0.5,\]</span> since Z is N(0,1) and the normal distribution is symmetric around its mean. We thus have that <span class="math display">\[\begin{align*}
P(2.65\le\overline X_{25}\le 3)&amp;=P(0\le Z\le 2.059)=P(Z\le 2.059)-P(Z\le 0)\\
&amp;= 0.9802-05=0.4802.
\end{align*}\]</span></p>
<p>We could also find the probabilities without finding the Z-scores:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"P(Xbar &lt;= 3) = "</span>, norm.cdf(<span class="dv">3</span>, loc <span class="op">=</span> <span class="fl">2.65</span>, scale <span class="op">=</span> np.sqrt(<span class="fl">0.0289</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>P(Xbar &lt;= 3) =  0.980244426611219</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"P(Xbar &lt;= 2.65) = "</span>, norm.cdf(<span class="dv">3</span>, loc <span class="op">=</span> <span class="fl">2.65</span>, scale <span class="op">=</span> np.sqrt(<span class="fl">0.0289</span>)) <span class="op">-</span> norm.cdf(<span class="fl">2.65</span>, loc <span class="op">=</span> <span class="fl">2.65</span>, scale <span class="op">=</span> np.sqrt(<span class="fl">0.0289</span>)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>P(Xbar &lt;= 2.65) =  0.480244426611219</code></pre>
</div>
</div>
<ol start="2" type="a">
<li>We then need to find the value of n that satisfies: <span class="math display">\[P(\overline X_{n} \le 3) = P\left(\frac{\overline X_{n}-\mu}{\sigma/\sqrt{n}}\le\frac{3-2.65}{0.85/\sqrt{n}}\right)=P(Z\le \frac{0.35}{0.85}\sqrt{n})=0.99.\]</span> The us then find the z-score that give a probability of 0.99 using the quantile function or percent point function (the inverse of cdf):</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(norm.ppf(<span class="fl">0.99</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.3263478740408408</code></pre>
</div>
</div>
<p>That is <span class="math inline">\(P(Z\le 2.3263) = 0.99\)</span>, so to find <span class="math inline">\(n\)</span> we need to solve <span class="math display">\[\frac{0.35}{0.85}\sqrt n = 2.3263\Leftrightarrow n=2.3263^2\frac{0.85^2}{0.35^2}=31.91\approx 32.\]</span> Note that we round off <span class="math inline">\(n\)</span> to an integer and we should here always round up to ensure that the probability is not less than 0.99.</p>
</details>
</section>
<section id="problem-43" class="level3">
<h3 class="anchored" data-anchor-id="problem-43">Problem 43</h3>
<p>The Central Limit Theorem states that the sample mean <span class="math inline">\(\bar X\)</span> follows an approximately normal distribution when the sample size is sufficiently large. More precisely, the theorem asserts that the standardized version of <span class="math inline">\(\bar X\)</span> given by <span class="math display">\[\frac{\bar X-\mu}{\sigma/\sqrt{n}},\]</span> converges in distribution to the standard normal distribution as <span class="math inline">\(n\)</span> increases.</p>
<p>How does this relate to the Law of Large Numbers? If the standardized <span class="math inline">\(\bar X\)</span> follows an approximate standard normal distribution, what does this imply about the distribution of <span class="math inline">\(\bar X\)</span> itself?</p>
<details>
<summary>
Show solutions
</summary>
<p>The Law of Large numbers states that <span class="math inline">\(\bar X\)</span> will approach <span class="math inline">\(\mu\)</span> when <span class="math inline">\(n\)</span> becomes large. The central limit theorem implies that <span class="math inline">\(\bar X\)</span> will follow a <span class="math inline">\(N(\mu, \sigma^2/n)\)</span> distribution asymptotically.</p>
</details>
</section>
<section id="problem-44" class="level3">
<h3 class="anchored" data-anchor-id="problem-44">Problem 44</h3>
<p>Suppose <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> are independent and identically distributed (i.i.d.) random variables from an exponential distribution with parameter <span class="math inline">\(\lambda &gt; 0\)</span>, i.e.,</p>
<p><span class="math display">\[f(x \mid \lambda) = \lambda e^{-\lambda x}, \quad x &gt; 0.\]</span></p>
<p>Find the Maximum Likelihood Estimator (MLE) for <span class="math inline">\(\lambda\)</span>.</p>
<details>
<summary>
Show solutions
</summary>
<p>The likelihood function is: <span class="math display">\[L(\lambda) = \prod_{i=1}^{n} \lambda e^{-\lambda X_i} = \lambda^n e^{-\lambda \sum X_i}.\]</span></p>
<p>The log-likelihood function is: <span class="math display">\[\ell(\lambda) = n \log \lambda - \lambda \sum X_i.\]</span></p>
<p>Differentiating with respect to <span class="math inline">\(\lambda\)</span>: <span class="math display">\[\frac{d\ell}{d\lambda} = \frac{n}{\lambda} - \sum X_i.\]</span></p>
<p>Setting it equal to zero: <span class="math display">\[\frac{n}{\lambda} = \sum X_i.\]</span></p>
<p>Solving for <span class="math inline">\(\lambda\)</span>: <span class="math display">\[\hat{\lambda} = \frac{n}{\sum X_i}.\]</span></p>
</details>
</section>
<section id="problem-45" class="level3">
<h3 class="anchored" data-anchor-id="problem-45">Problem 45</h3>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be i.i.d. random variables from a normal distribution with unknown mean <span class="math inline">\(\mu\)</span> and known variance <span class="math inline">\(\sigma^2\)</span>. That is, <span class="math display">\[X_i \sim N(\mu, \sigma^2),\]</span> such that the density of the X’s is <span class="math display">\[f(x,\mu,\sigma)=\frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(x - \mu)^2}{2\sigma^2}\right).\]</span></p>
<p>Find the MLE of <span class="math inline">\(\mu\)</span>.</p>
<details>
<summary>
Show solutions
</summary>
<p>The likelihood function is: <span class="math display">\[L(\mu) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(X_i - \mu)^2}{2\sigma^2} \right).\]</span></p>
<p>The log-likelihood function is: <span class="math display">\[\ell(\mu) = -\frac{n}{2} \log (2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (X_i - \mu)^2.\]</span></p>
<p>Differentiating with respect to <span class="math inline">\(\mu\)</span>: <span class="math display">\[\frac{d\ell}{d\mu} = \frac{1}{\sigma^2} \sum_{i=1}^{n} (X_i - \mu).\]</span></p>
<p>Setting it equal to zero: <span class="math display">\[\sum_{i=1}^{n} (X_i - \mu) = 0.\]</span></p>
<p>Solving for <span class="math inline">\(\mu\)</span>: <span class="math display">\[\hat{\mu} = \frac{1}{n} \sum_{i=1}^{n} X_i.\]</span></p>
</details>
</section>
<section id="problem-46" class="level3">
<h3 class="anchored" data-anchor-id="problem-46">Problem 46</h3>
<p>Let <span class="math inline">\(X_1, X_2, \dots, X_n\)</span> be i.i.d. random variables from a Bernoulli distribution with unknown parameter <span class="math inline">\(p\)</span>. That is, <span class="math display">\[P(X_i = 1) = p, \quad P(X_i = 0) = 1 - p.\]</span> Find the MLE for <span class="math inline">\(p\)</span>.</p>
<p>Hint: We can also write the Bernoulli distribution as <span class="math inline">\(P(X=x) =p^x(1-p)^{1-x}\)</span>, where <span class="math inline">\(x\in \{0,1\}\)</span>.</p>
<details>
<summary>
Show solutions
</summary>
<p>The likelihood function is: <span class="math display">\[L(p) = \prod_{i=1}^{n} p^{X_i} (1 - p)^{1 - X_i}.\]</span></p>
<p>The log-likelihood function is: <span class="math display">\[\ell(p) = \sum_{i=1}^{n} X_i \log p + (1 - X_i) \log (1 - p).\]</span></p>
<p>Differentiating with respect to <span class="math inline">\(p\)</span>: <span class="math display">\[\frac{d\ell}{dp} = \sum_{i=1}^{n} \frac{X_i}{p} - \sum_{i=1}^{n} \frac{1 - X_i}{1 - p}.\]</span></p>
<p>Setting it equal to zero: <span class="math display">\[\sum X_i \frac{1}{p} - \sum (1 - X_i) \frac{1}{1 - p} = 0.\]</span> Rearranging: <span class="math display">\[\sum X_i (1 - p) = (n - \sum X_i) p.\]</span></p>
<p>Solving for <span class="math inline">\(p\)</span>: <span class="math display">\[\hat{p} = \frac{1}{n} \sum X_i.\]</span></p>
</details>
</section>
<section id="problem-47" class="level3">
<h3 class="anchored" data-anchor-id="problem-47">Problem 47</h3>
<p>Let <span class="math inline">\(\hat{\theta}\)</span> be an estimator of a parameter <span class="math inline">\(\theta\)</span>. The bootstrap estimate of the bias is given by:</p>
<p><span class="math display">\[\hat{\text{Bias}} = \frac{1}{B} \sum_{b=1}^{B} \hat{\theta}^*_b - \hat{\theta},\]</span></p>
<p>where <span class="math inline">\(\hat{\theta}^*_b\)</span> is the estimate from bootstrap sample <span class="math inline">\(b\)</span>.</p>
<p>Use bootstrap resampling to estimate the bias of the maximum likelihood estimator of the variance;<span class="math display">\[s^2=\frac1n \sum_{i}(x_i-\bar x)^2,\]</span> for a set of data <span class="math inline">\(x_1,\ldots, x_n\)</span>.</p>
<p>Describe the procedure and discuss the sign of the bias. If you want to implement the code, use the following data set:</p>
<p><span class="math display">\[X = \{4.2, 3.9, 5.1, 4.8, 4.3, 5.0, 3.7, 4.5, 4.9, 4.6\}.\]</span></p>
<details>
<summary>
Show solutions
</summary>
<ol type="1">
<li>Compute the sample variance <span class="math inline">\(s^2\)</span> from the original dataset.</li>
<li>Generate 1000 bootstrap samples and compute <span class="math inline">\(s^2\)</span> for each.</li>
<li>Compute the bootstrap estimate of bias using the formula above.</li>
<li>Interpret the result: If the bias is positive, <span class="math inline">\(s^2\)</span> is overestimating the true variance; if negative, it is underestimating.</li>
</ol>
</details>
</section>
<section id="problem-48" class="level3">
<h3 class="anchored" data-anchor-id="problem-48">Problem 48</h3>
<p>When playing the casino game american roulette, there are 38 possible outcomes: 0,00, and 1-36. The 0 and 00 are colored green, while odd numbers from 1-35 are black and even numbers from 2-36 are red.</p>
<ol type="a">
<li>What is the probability of winning if you bet on a black outcome?</li>
</ol>
<p>A gambler has $100 and bets $1 each time he plays. He plays until he is either out of money or has $150.</p>
<ol start="2" type="a">
<li><p>How would you construct a Monte Carlo simulation of a situation where you always bet on black, and want to find the probability of going bankrupt.</p></li>
<li><p>What would the probability be of the gambler reaches his goal of $150?</p></li>
</ol>
<details>
<summary>
Show solutions
</summary>
<ol type="a">
<li><p>The probability of winning when betting on black is <span class="math inline">\(18/38=0.474\)</span></p></li>
<li><p>It would make sense to use a while loop and continue to simulate unless the gambler is bankrupt or has $200. To simulate the game, use a Bernoulli distribution for each game with success probability <span class="math inline">\(18/38=0.474\)</span>. If the Bernoulli variable is 1, increase the “bank” of the gambler by 1 dollar. If it is 0, decrease it by 1 dollar. Repeat the game 10 000 times and calculate the relative frequency of going bankrupt.</p></li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">123</span>)</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> simulate_game_simple(starting_money<span class="op">=</span><span class="dv">100</span>, goal_money<span class="op">=</span><span class="dv">150</span>, bet_amount<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    money <span class="op">=</span> starting_money</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="dv">0</span> <span class="op">&lt;</span> money <span class="op">&lt;</span> goal_money:</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simulate the outcome: +1 with prob 18/38, -1 with prob 20/38</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        outcome <span class="op">=</span> random.choices([<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], weights<span class="op">=</span>[<span class="dv">20</span>, <span class="dv">18</span>])[<span class="dv">0</span>]</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        money <span class="op">+=</span> outcome <span class="op">*</span> bet_amount</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> money <span class="op">==</span> <span class="dv">0</span>  <span class="co"># True if bankrupt</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> monte_carlo_simulation(n_simulations<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    bankrupt_count <span class="op">=</span> <span class="bu">sum</span>(simulate_game_simple() <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n_simulations))</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> bankrupt_count <span class="op">/</span> n_simulations</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the simplified simulation</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>estimated_prob <span class="op">=</span> monte_carlo_simulation(<span class="dv">10000</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Estimated probability of going bankrupt: </span><span class="sc">{</span>estimated_prob<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Estimated probability of going bankrupt: 0.9949</code></pre>
</div>
</div>
<ol start="3" type="a">
<li>In the end, there are only two outcomes of the experiment. Either the gambler ends up with $0 (bankrupt) or $150. The probability achieving $150 would therefore be 1-the probability of going bankrupt.</li>
</ol>
<p>From the python simulation above, it would then be <span class="math display">\[1-P(bankrupt)=1-0.9949=0.0051\]</span></p>
</details>
</section>
<section id="problem-49" class="level3">
<h3 class="anchored" data-anchor-id="problem-49">Problem 49</h3>
<p>Let <span class="math inline">\(X_1,\ldots, X_n\)</span> be a random sample from the probability density function <span class="math display">\[f(x|\theta) = \theta x^{\theta -1},\quad 0&lt;\theta&lt;\infty,\quad 0\le x\le1.\]</span> Find the MLE of <span class="math inline">\(\theta\)</span>.</p>
<details>
<summary>
Show solutions
</summary>
<p><span class="math display">\[L(\theta)=f(x_1,\ldots, x_n|\theta) = \theta^n \prod_{i=1}^nx_i^{\theta -1}\]</span> <span class="math display">\[\log L = n\log \theta + (\theta-1)\sum_{i=1}^n\log x_i\]</span> <span class="math display">\[\frac{\partial \log L}{\partial \theta} = \frac{n}{\theta} + \sum_{i=1}^n\log x_i=0\]</span> <span class="math display">\[\widehat \theta = \frac{-n}{\sum_{i=1}^n \log x_i}.\]</span></p>
</details>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./3-python.html" class="pagination-link" aria-label="Python">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Python</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./4-intro.html" class="pagination-link" aria-label="Introduction">
        <span class="nav-page-text">Introduction</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>